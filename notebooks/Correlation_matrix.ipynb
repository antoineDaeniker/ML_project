{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "czech-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../')\n",
    "from utils.implementation_utils import *\n",
    "from utils.preprocessing_utils import *\n",
    "import datetime\n",
    "from model import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5613650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(w, X_test, y_test):\n",
    "    y_pred = predict_labels(w, X_test)\n",
    "    y_test[np.where(y_test <= 0)] = -1\n",
    "    accuracy = get_accuracy(y_pred, y_test)\n",
    "    print(f'Model accuracy: {accuracy}')\n",
    "    return accuracy\n",
    "\n",
    "def reg_logistic_regression_(y, tx, lambda_ , initial_w, max_iters, gamma):\n",
    "    w = initial_w\n",
    "    ws_list = []\n",
    "    for iter in range(max_iters):\n",
    "        loss, grad = penalized_logistic_regression(y, tx, w, lambda_)\n",
    "        w = w - gamma * grad\n",
    "        if (iter % 100 == 0):\n",
    "            ws_list.append(w)\n",
    "    return w, loss, ws_list\n",
    "\n",
    "def train_(X, y, rmv_idx, method=reg_logistic_regression_, max_iters=800, gamma=1e-7, lambda_=1e-8, batch_size=1,\n",
    "          start_degree=-3, end_degree=8, include_half=True, include_cross_terms=True):\n",
    "\n",
    "    if method == reg_logistic_regression_:\n",
    "        w, loss, ws_list = reg_logistic_regression_(\n",
    "            y=y,\n",
    "            tx=X,\n",
    "            lambda_=lambda_,\n",
    "            initial_w=np.zeros(X.shape[1]),\n",
    "            max_iters=max_iters,\n",
    "            gamma=gamma,\n",
    "        )\n",
    "    elif method == ridge_regression:\n",
    "        w, loss = ridge_regression(y, X, lambda_=1e-8)\n",
    "    else:\n",
    "        raise ValueError('Please specify valid method name')\n",
    "\n",
    "    logger.info(f'Final loss value for trained model: {loss}')\n",
    "\n",
    "    # for i in rmv_idx:\n",
    "    #     w = np.insert(w, i, 0)\n",
    "\n",
    "    return w, loss, ws_list\n",
    "\n",
    "\n",
    "def run_model_split_(save_weights=False, retrain=True, internal_test=True, create_submission=False, add_bias_term=True,\n",
    "                    apply_cross_validation=True):\n",
    "    y, X, Xt, ids = load_csv_data('../data/train.csv')\n",
    "    print('Data shape: ', y.shape, X.shape)\n",
    "    X_list, y_list, rmv_idx_list = preprocess_train_data_split(X, y)  # doesn't do any train / test splitting\n",
    "    ws = []\n",
    "    losses = []\n",
    "    train_acc_list_all = []\n",
    "    test_acc_list_all  = []\n",
    "    for i, (y, X, rmv_idx), in enumerate(zip(y_list, X_list, rmv_idx_list)):\n",
    "        if add_bias_term:\n",
    "            X = np.concatenate((np.ones(X.shape[0])[:, np.newaxis], X), axis=1)\n",
    "        w_split = []\n",
    "        losses_split = []\n",
    "        if apply_cross_validation:\n",
    "            k_fold = 10\n",
    "            k_indices = build_k_indices(y, k_fold)\n",
    "        else:\n",
    "            k_fold = 1\n",
    "        for k in range(1):\n",
    "            start_time = datetime.now()\n",
    "            if apply_cross_validation:\n",
    "                X_train, y_train, X_test, y_test = split_cross_validation(y, X, k_indices, k)\n",
    "                y_train_dist = np.asarray((np.unique(y_train, return_counts=True))).T\n",
    "                y_test_dist = np.asarray((np.unique(y_test, return_counts=True))).T\n",
    "                # with np.printoptions(precision=0, suppress=True):\n",
    "                #    print(f'y_train distribution: {y_train_dist} \\ny_test distribution: {y_test_dist}')\n",
    "            else:\n",
    "                X_train, y_train = X, y\n",
    "\n",
    "            if not retrain:\n",
    "                w = np.loadtxt('sgd_model.csv', delimiter=',')\n",
    "            else:\n",
    "                if apply_cross_validation:\n",
    "                    current_config = get_run_configs(k=k_fold)[k]\n",
    "                    print(f'Training with config: {current_config}')\n",
    "                    w, loss, ws_list = train_(X_train, y_train, rmv_idx, max_iters=20000)\n",
    "                else:\n",
    "                    w, loss = train(X_train, y_train, rmv_idx)\n",
    "                losses_split.append(loss)\n",
    "                w_split.append(w)\n",
    "                end_time = datetime.now()\n",
    "                exection_time = (end_time - start_time).total_seconds()\n",
    "                print(\"Model training time={t:.3f} seconds\".format(t=exection_time))\n",
    "\n",
    "            if internal_test and apply_cross_validation:\n",
    "                print(f'Test for datasplit : {i} and k {k}')\n",
    "                train_acc_list = []\n",
    "                test_acc_list  = []\n",
    "                for w_ in ws_list:\n",
    "                    train_acc_list.append(test(w_, X_train, y_train))\n",
    "                    test_acc_list.append(test(w_, X_test, y_test))\n",
    "        train_acc_list_all.append(train_acc_list)\n",
    "        test_acc_list_all.append(test_acc_list)\n",
    "        \n",
    "    return train_acc_list_all, test_acc_list_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb6955a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (250000,) (250000, 30)\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 340 terms and 24 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 399 terms and 35 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 675 terms and 50 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 675 terms and 50 zero terms.\n",
      "Training with config: {'method': <function reg_logistic_regression at 0x7fd8263ebf80>, 'max_iters': 2000, 'lambda_': 1e-08, 'start_degree': -3, 'end_degree': 8, 'include_half': True, 'include_cross_terms': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/implementation_utils.py:261: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_i = y.T.dot(np.log(pred)) + (1 - y).T.dot(np.log(1 - pred))\n",
      "../utils/implementation_utils.py:255: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training time=1106.621 seconds\n",
      "Test for datasplit : 0 and k 0\n",
      "y_pred mean :  -0.008862124068507102\n",
      "Model accuracy: 73.90651586427785\n",
      "y_pred mean :  -0.009161310114874031\n",
      "Model accuracy: 73.61625462916625\n",
      "y_pred mean :  -0.8335340009484342\n",
      "Model accuracy: 77.84672872251693\n",
      "y_pred mean :  -0.8453746954592536\n",
      "Model accuracy: 77.63987588829947\n",
      "y_pred mean :  -1.597131011594119\n",
      "Model accuracy: 79.34919205062334\n",
      "y_pred mean :  -1.6150509221268472\n",
      "Model accuracy: 79.23130817735962\n",
      "y_pred mean :  -2.3334428840263306\n",
      "Model accuracy: 80.0754011944083\n",
      "y_pred mean :  -2.356948088557722\n",
      "Model accuracy: 79.70173155840256\n",
      "y_pred mean :  -3.055177383971824\n",
      "Model accuracy: 80.48577052680746\n",
      "y_pred mean :  -3.084263127464083\n",
      "Model accuracy: 80.1621459313382\n",
      "y_pred mean :  -3.7683939138345326\n",
      "Model accuracy: 80.72932305741834\n",
      "y_pred mean :  -3.8031076679793023\n",
      "Model accuracy: 80.4724251826644\n",
      "y_pred mean :  -4.476324700113987\n",
      "Model accuracy: 80.85054326671782\n",
      "y_pred mean :  -4.516696126397017\n",
      "Model accuracy: 80.69262336102493\n",
      "y_pred mean :  -5.180775618828964\n",
      "Model accuracy: 80.9561939078504\n",
      "y_pred mean :  -5.226851793114638\n",
      "Model accuracy: 80.81273145831248\n",
      "y_pred mean :  -5.882820862670468\n",
      "Model accuracy: 81.02180851655379\n",
      "y_pred mean :  -5.934644397596456\n",
      "Model accuracy: 80.91282153938545\n",
      "y_pred mean :  -6.583138713749037\n",
      "Model accuracy: 81.06629299703066\n",
      "y_pred mean :  -6.640742475388305\n",
      "Model accuracy: 80.97287558802923\n",
      "y_pred mean :  -7.2821767171457745\n",
      "Model accuracy: 81.0940957973287\n",
      "y_pred mean :  -7.345585158316509\n",
      "Model accuracy: 80.99289360424382\n",
      "y_pred mean :  -7.980240361047757\n",
      "Model accuracy: 81.11522592555522\n",
      "y_pred mean :  -8.04947270647511\n",
      "Model accuracy: 81.01291162045841\n",
      "y_pred mean :  -8.677544445797738\n",
      "Model accuracy: 81.13524394176982\n",
      "y_pred mean :  -8.752616876860897\n",
      "Model accuracy: 81.0529476528876\n",
      "y_pred mean :  -9.374244323304302\n",
      "Model accuracy: 81.15748618200826\n",
      "y_pred mean :  -9.455170695961057\n",
      "Model accuracy: 81.07296566910219\n",
      "y_pred mean :  -10.070455365476128\n",
      "Model accuracy: 81.18195264627053\n",
      "y_pred mean :  -10.157247275401499\n",
      "Model accuracy: 81.13301971774597\n",
      "y_pred mean :  -10.766265260026895\n",
      "Model accuracy: 81.19863432644937\n",
      "y_pred mean :  -10.85893214989007\n",
      "Model accuracy: 81.15303773396056\n",
      "y_pred mean :  -11.46174193434344\n",
      "Model accuracy: 81.21420389461626\n",
      "y_pred mean :  -11.560291386260287\n",
      "Model accuracy: 81.17305575017515\n",
      "y_pred mean :  -12.15693883531998\n",
      "Model accuracy: 81.23310979881894\n",
      "y_pred mean :  -12.261376930123495\n",
      "Model accuracy: 81.18306475828246\n",
      "y_pred mean :  -12.85189857634866\n",
      "Model accuracy: 81.24423091893816\n",
      "y_pred mean :  -12.962230217085539\n",
      "Model accuracy: 81.18306475828246\n",
      "y_pred mean :  -13.546655531637606\n",
      "Model accuracy: 81.24979147899776\n",
      "y_pred mean :  -13.662884697567725\n",
      "Model accuracy: 81.20308277449705\n",
      "y_pred mean :  -14.241237722616312\n",
      "Model accuracy: 81.2564641510693\n",
      "y_pred mean :  -14.363367657942257\n",
      "Model accuracy: 81.21309178260434\n",
      "y_pred mean :  -14.935668212892217\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -15.06370156540853\n",
      "Model accuracy: 81.22310079071164\n",
      "y_pred mean :  -15.629966154224139\n",
      "Model accuracy: 81.26424893515275\n",
      "y_pred mean :  -15.763905078563038\n",
      "Model accuracy: 81.22310079071164\n",
      "y_pred mean :  -16.324147580438925\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -16.46399381707028\n",
      "Model accuracy: 81.23310979881894\n",
      "y_pred mean :  -17.01822601676128\n",
      "Model accuracy: 81.26869738320043\n",
      "y_pred mean :  -17.163980954457983\n",
      "Model accuracy: 81.24311880692623\n",
      "y_pred mean :  -17.712212952321558\n",
      "Model accuracy: 81.2720337192362\n",
      "y_pred mean :  -17.86387767918139\n",
      "Model accuracy: 81.24311880692623\n",
      "y_pred mean :  -18.406118210120322\n",
      "Model accuracy: 81.27981850331966\n",
      "y_pred mean :  -18.563693556427953\n",
      "Model accuracy: 81.25312781503354\n",
      "y_pred mean :  -19.09995023934428\n",
      "Model accuracy: 81.2820427273435\n",
      "y_pred mean :  -19.263436814369243\n",
      "Model accuracy: 81.25312781503354\n",
      "y_pred mean :  -19.793716348310515\n",
      "Model accuracy: 81.28871539941503\n",
      "y_pred mean :  -19.963114572379524\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -20.487422891594324\n",
      "Model accuracy: 81.28649117539119\n",
      "y_pred mean :  -20.662733024303247\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -21.181075421491396\n",
      "Model accuracy: 81.28649117539119\n",
      "y_pred mean :  -21.36229758663396\n",
      "Model accuracy: 81.25312781503354\n",
      "y_pred mean :  -21.87467881148611\n",
      "Model accuracy: 81.28982751142695\n",
      "y_pred mean :  -22.06181301910316\n",
      "Model accuracy: 81.25312781503354\n",
      "y_pred mean :  -22.568237357574358\n",
      "Model accuracy: 81.29872440752233\n",
      "y_pred mean :  -22.76128352342685\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -23.26175486193773\n",
      "Model accuracy: 81.29983651953425\n",
      "y_pred mean :  -23.460712824648382\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -23.95523470245295\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -24.16010423852855\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -24.648679890757418\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -24.859460727684684\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -25.342093121010436\n",
      "Model accuracy: 81.30650919160578\n",
      "y_pred mean :  -25.558784948605844\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -26.035476811044568\n",
      "Model accuracy: 81.3076213036177\n",
      "y_pred mean :  -26.258079291229294\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -26.728833137258146\n",
      "Model accuracy: 81.3076213036177\n",
      "y_pred mean :  -26.957345912420582\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -27.422164064331895\n",
      "Model accuracy: 81.30984552764154\n",
      "y_pred mean :  -27.65658676443126\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -28.11547137064441\n",
      "Model accuracy: 81.30984552764154\n",
      "y_pred mean :  -28.355803619199325\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -28.808756670095676\n",
      "Model accuracy: 81.30984552764154\n",
      "y_pred mean :  -29.054998089191354\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -29.502021430917825\n",
      "Model accuracy: 81.31206975166539\n",
      "y_pred mean :  -29.754171645354475\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -30.195266991947395\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -30.453325632641704\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -30.888494576750677\n",
      "Model accuracy: 81.31429397568922\n",
      "y_pred mean :  -31.15246128349105\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -31.581705305925606\n",
      "Model accuracy: 81.31429397568922\n",
      "y_pred mean :  -31.851579729571263\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -32.274900207849704\n",
      "Model accuracy: 81.31540608770115\n",
      "y_pred mean :  -32.55068201205362\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -32.96808022809881\n",
      "Model accuracy: 81.31429397568922\n",
      "y_pred mean :  -33.249769090624945\n",
      "Model accuracy: 81.26313682314083\n",
      "y_pred mean :  -33.6612462377246\n",
      "Model accuracy: 81.31651819971307\n",
      "y_pred mean :  -33.94884185142114\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -34.35439904055009\n",
      "Model accuracy: 81.31985453574885\n",
      "y_pred mean :  -34.647901114032535\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -35.04753937961654\n",
      "Model accuracy: 81.31874242373692\n",
      "y_pred mean :  -35.34694763770705\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -35.74066794289469\n",
      "Model accuracy: 81.31985453574885\n",
      "y_pred mean :  -36.04598212685821\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -36.43378536835795\n",
      "Model accuracy: 81.32207875977268\n",
      "y_pred mean :  -36.74500523596933\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -37.12689224849868\n",
      "Model accuracy: 81.32430298379653\n",
      "y_pred mean :  -37.444017573970704\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -37.819989134358\n",
      "Model accuracy: 81.32541509580845\n",
      "y_pred mean :  -38.14301970815552\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -38.513076539130196\n",
      "Model accuracy: 81.32541509580845\n",
      "y_pred mean :  -38.842012167691756\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -39.206154941392455\n",
      "Model accuracy: 81.32541509580845\n",
      "y_pred mean :  -39.540995446778005\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -39.89922478800609\n",
      "Model accuracy: 81.32875143184421\n",
      "y_pred mean :  -40.239970007485915\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -40.5922864967265\n",
      "Model accuracy: 81.32875143184421\n",
      "y_pred mean :  -40.938936282324796\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -41.28534045855681\n",
      "Model accuracy: 81.32763931983229\n",
      "y_pred mean :  -41.63789467656065\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -41.9783870398736\n",
      "Model accuracy: 81.32875143184421\n",
      "y_pred mean :  -42.33684557031681\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -42.671426584350314\n",
      "Model accuracy: 81.32875143184421\n",
      "y_pred mean :  -43.03578932047985\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -43.364459414700995\n",
      "Model accuracy: 81.32875143184421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -43.73472626243242\n",
      "Model accuracy: 81.27314583124813\n",
      "y_pred mean :  -44.057485834263005\n",
      "Model accuracy: 81.32986354385613\n",
      "y_pred mean :  -44.43365671163048\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -44.750506128437124\n",
      "Model accuracy: 81.33097565586806\n",
      "y_pred mean :  -45.1325809650424\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -45.44352056599857\n",
      "Model accuracy: 81.33208776787998\n",
      "y_pred mean :  -45.83149930246269\n",
      "Model accuracy: 81.28315483935542\n",
      "y_pred mean :  -46.136529400293426\n",
      "Model accuracy: 81.33208776787998\n",
      "y_pred mean :  -46.53041198771411\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -46.829532870331455\n",
      "Model accuracy: 81.33431199190383\n",
      "y_pred mean :  -47.22931926974886\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -47.52253120178596\n",
      "Model accuracy: 81.33431199190383\n",
      "y_pred mean :  -47.928221383658645\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -48.21552460790982\n",
      "Model accuracy: 81.33542410391574\n",
      "y_pred mean :  -48.62711855160259\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -48.90851329037613\n",
      "Model accuracy: 81.33431199190383\n",
      "y_pred mean :  -49.32601098366098\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -49.601497440049876\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -50.02489887862119\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -50.29447723769827\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -50.723782424702755\n",
      "Model accuracy: 81.29316384746272\n",
      "y_pred mean :  -50.98745285464458\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -51.4226618002267\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -51.68042445337121\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -52.12153717423427\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -52.37339218807616\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -52.820408707059535\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -53.066356205187844\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -53.51927655086002\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -53.759316643840705\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -54.21814085010863\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -54.45227363631639\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -54.917001742050594\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -55.145227308452625\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -55.615859357128215\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -55.838177780022576\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -56.31471381937578\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -56.53112516508765\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -57.01356524678761\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -57.224069572325426\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -57.71241375166098\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -57.91701110533529\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -58.41125944091636\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -58.609949862922605\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -59.11010241639587\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -59.30288593936472\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -59.80894277514306\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -59.99581942465865\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -60.50778060966411\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -60.68875040475266\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -61.20661600817246\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -61.38167896176309\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -61.90544905481818\n",
      "Model accuracy: 81.30317285557001\n",
      "y_pred mean :  -62.07460517417716\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -62.60427982990297\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -62.767529117043026\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -63.30310841008203\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -63.4604508621481\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -64.00193486855358\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -64.1533704781862\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -64.700759275237\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -64.84628803091465\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -65.39958169694044\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -65.53920358330191\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -66.09840219751841\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -66.23211719566646\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -66.79722083802037\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -66.9250289258077\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -67.49603767683081\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -67.61793882912872\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -68.1948527698011\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -68.31084695875298\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -68.89366617037437\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -69.00375336563313\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -69.5924779297026\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -69.69665809865478\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -70.29128809675804\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -70.38956120473422\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -70.99009671843841\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -71.08246272891014\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -71.6889038396656\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -71.77536271443134\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -72.38770950348014\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -72.4682612028394\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -73.08651375113023\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -73.16115823404633\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -73.78531662215545\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -73.85405384640907\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -74.4841181544671\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -74.54694807679938\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -75.18291838442353\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -75.23984096067068\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -75.88171734690228\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -75.93273253212097\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -76.5805150753679\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -76.6256228239528\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -77.2793116019366\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -77.31851186773049\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -77.97810695743796\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -78.01139969383385\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -78.6769011714727\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -78.70428633150996\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -79.37569427246879\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -79.39717180892164\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -80.07448628773336\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -80.0900561531945\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -80.7732772435034\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -80.78293939046092\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -81.47206716499316\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -81.47582154590238\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -82.17085607643963\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -82.16870264378966\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -82.86964400114566\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -82.86158270752095\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -83.56843096152092\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -83.55446175965858\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -84.26721697912122\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -84.24733982196365\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -84.96600207468585\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -84.94021691542953\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -85.66478626817306\n",
      "Model accuracy: 81.3231908717846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -85.63309306031314\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -86.3635695787938\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -86.32596827616555\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -87.06235202504433\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -87.01884258186081\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -87.76113362473679\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -87.7117159956232\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -88.45991439502852\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -88.40458853505415\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -89.15869435245047\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -89.09746021715715\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -89.85747351293374\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -89.79033105836182\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -90.55625189183503\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -90.48320107454683\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -91.25502950396115\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -91.17607028106212\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -91.95380636359225\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -91.86893869274999\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -92.65258248450418\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -92.5618063239651\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -93.35135787998956\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -93.25467318859376\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -94.05013256287818\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -93.94753930007248\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -94.74890654555628\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -94.64040467140573\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -95.44767983998535\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -95.33326931518269\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -96.1464524577196\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -96.02613324359353\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -96.84522440992292\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -96.71899646844507\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -97.5439957073852\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -97.41185900117551\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -98.2427663605377\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -98.10472085286871\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -98.9415363794679\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -98.7975820342678\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -99.64030577393368\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -99.4904425557885\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -100.33907455337666\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -100.18330242753153\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -101.03784272693561\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -100.87616165929461\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -101.73661030345846\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -101.56902026058417\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -102.43537729151429\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -102.26187824062612\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -103.13414369940459\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -102.95473560837704\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -103.83290953517444\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -103.64759237253354\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -104.53167480662239\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -104.34044854154311\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -105.2304395213111\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -105.03330412361235\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -105.92920368657607\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -105.72615912671681\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -106.62796730953545\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -106.41901355860924\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -107.32673039709833\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -107.11186742682817\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -108.02549295597348\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -107.80472073870563\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -108.72425499267707\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -108.49757350137482\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -109.4230165135404\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -109.19042572177754\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -110.1217775247173\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -109.88327740667111\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -110.82053803219105\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -110.57612856263549\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -111.5192980417815\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -111.26897919607926\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -112.21805755915099\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -111.96182931324621\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -112.91681658981086\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -112.65467892022129\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -113.61557513912734\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -113.34752802293609\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -114.314333212327\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -114.040376627175\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -115.01309081450269\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -114.73322473857964\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -115.71184795061805\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -115.42607236265486\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -116.41060462551323\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -116.11891950477296\n",
      "Model accuracy: 81.34098466397536\n",
      "y_pred mean :  -117.10936084390903\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -116.81176617017898\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -117.80811661041206\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -117.50461236399455\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -118.50687192951862\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -118.19745809122283\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -119.20562680561912\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -118.89030335675245\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -119.9043812430023\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -119.58314816536154\n",
      "Model accuracy: 81.33987255196344\n",
      "y_pred mean :  -120.6031352458588\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -120.2759925217216\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -121.30188881828501\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -120.96883643040124\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -122.00064196428653\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -121.6616798958696\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -122.69939468778165\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -122.3545229225002\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -123.39814699260474\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -123.04736551457358\n",
      "Model accuracy: 81.33876043995151\n",
      "y_pred mean :  -124.096898882509\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -123.74020767628107\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -124.7956503611697\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -124.43304941172752\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -125.49440143218723\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -125.12589072493432\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -126.19315209908943\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -125.8187316198423\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -126.89190236533466\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -126.51157210031417\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -127.5906522343139\n",
      "Model accuracy: 81.3231908717846\n",
      "y_pred mean :  -127.20441217013736\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -128.28940170935348\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -127.89725183302636\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -128.98815079371727\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -128.5900910926255\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -129.68689949060902\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -129.28292995251064\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -130.3856478031743\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -129.97576841619207\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -131.08439573450278\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -130.66860648711588\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -131.7831432876299\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -131.3614441686673\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -132.48189046553955\n",
      "Model accuracy: 81.31318186367731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -132.05428146417097\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -133.1806372711643\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -132.74711837689406\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -133.87938370738874\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -133.4399549100477\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -134.57812977705018\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -134.13279106678894\n",
      "Model accuracy: 81.33653621592767\n",
      "y_pred mean :  -135.2768754829407\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -134.82562685022225\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -135.97562082780848\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -135.51846226340126\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -136.6743658143593\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -136.21129730933026\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -137.373110445258\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -136.9041319909655\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -138.07185472312952\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -137.59696631121722\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -138.77059865056057\n",
      "Model accuracy: 81.31318186367731\n",
      "y_pred mean :  -138.28980027295023\n",
      "Model accuracy: 81.33764832793959\n",
      "y_pred mean :  -139.46934223010052\n",
      "Model accuracy: 81.31318186367731\n",
      "Training with config: {'method': <function reg_logistic_regression at 0x7fd8263ebf80>, 'max_iters': 2000, 'lambda_': 1e-08, 'start_degree': -3, 'end_degree': 8, 'include_half': True, 'include_cross_terms': True}\n",
      "Model training time=1034.212 seconds\n",
      "Test for datasplit : 1 and k 0\n",
      "y_pred mean :  -0.005517848484520477\n",
      "Model accuracy: 69.44802682486458\n",
      "y_pred mean :  -0.005192686345306613\n",
      "Model accuracy: 69.26747485168946\n",
      "y_pred mean :  -0.5256509444153462\n",
      "Model accuracy: 72.28383916544865\n",
      "y_pred mean :  -0.5086624434782367\n",
      "Model accuracy: 72.42713438225432\n",
      "y_pred mean :  -1.0163509151296428\n",
      "Model accuracy: 73.38291347834809\n",
      "y_pred mean :  -0.9886297811746819\n",
      "Model accuracy: 73.42017023471756\n",
      "y_pred mean :  -1.4916060186181805\n",
      "Model accuracy: 74.01484538446107\n",
      "y_pred mean :  -1.4538540336062438\n",
      "Model accuracy: 73.91023987619293\n",
      "y_pred mean :  -1.9567375217531882\n",
      "Model accuracy: 74.32293010059324\n",
      "y_pred mean :  -1.9091858762444085\n",
      "Model accuracy: 74.4003095176683\n",
      "y_pred mean :  -2.414842615510369\n",
      "Model accuracy: 74.60665462986846\n",
      "y_pred mean :  -2.3576106529556045\n",
      "Model accuracy: 74.63244776889347\n",
      "y_pred mean :  -2.8678922540785874\n",
      "Model accuracy: 74.79150545954776\n",
      "y_pred mean :  -2.8010370546467858\n",
      "Model accuracy: 74.74851689450607\n",
      "y_pred mean :  -3.3171824219278445\n",
      "Model accuracy: 74.95772791104233\n",
      "y_pred mean :  -3.240712290806945\n",
      "Model accuracy: 74.98065514573123\n",
      "y_pred mean :  -3.7636082567093863\n",
      "Model accuracy: 75.0580345628063\n",
      "y_pred mean :  -3.6775434963920537\n",
      "Model accuracy: 75.04513799329378\n",
      "y_pred mean :  -4.207805691881811\n",
      "Model accuracy: 75.1569082624022\n",
      "y_pred mean :  -4.1121678719206285\n",
      "Model accuracy: 75.01934485426877\n",
      "y_pred mean :  -4.6502358608934955\n",
      "Model accuracy: 75.22855587080504\n",
      "y_pred mean :  -4.545041444420242\n",
      "Model accuracy: 75.09672427134382\n",
      "y_pred mean :  -5.091244362392311\n",
      "Model accuracy: 75.30880119221621\n",
      "y_pred mean :  -4.976502718669895\n",
      "Model accuracy: 75.12251741036884\n",
      "y_pred mean :  -5.531093731424772\n",
      "Model accuracy: 75.36468632677041\n",
      "y_pred mean :  -5.406809774461161\n",
      "Model accuracy: 75.17410368841888\n",
      "y_pred mean :  -5.969984598539142\n",
      "Model accuracy: 75.39621127446766\n",
      "y_pred mean :  -5.8361613382722215\n",
      "Model accuracy: 75.17410368841888\n",
      "y_pred mean :  -6.4080724104118625\n",
      "Model accuracy: 75.404808987476\n",
      "y_pred mean :  -6.2647119369048285\n",
      "Model accuracy: 75.22568996646892\n",
      "y_pred mean :  -6.845479641693955\n",
      "Model accuracy: 75.43919983950936\n",
      "y_pred mean :  -6.692583404827318\n",
      "Model accuracy: 75.21279339695641\n",
      "y_pred mean :  -7.28230433668006\n",
      "Model accuracy: 75.46499297853438\n",
      "y_pred mean :  -7.119873243978173\n",
      "Model accuracy: 75.17410368841888\n",
      "y_pred mean :  -7.718626096132324\n",
      "Model accuracy: 75.49365202189551\n",
      "y_pred mean :  -7.546660584732495\n",
      "Model accuracy: 75.1998968274439\n",
      "y_pred mean :  -8.15451034639536\n",
      "Model accuracy: 75.50511563923996\n",
      "y_pred mean :  -7.97301045758874\n",
      "Model accuracy: 75.17410368841888\n",
      "y_pred mean :  -8.590011443977339\n",
      "Model accuracy: 75.51084744791218\n",
      "y_pred mean :  -8.398976898619821\n",
      "Model accuracy: 75.16120711890638\n",
      "y_pred mean :  -9.025174975796364\n",
      "Model accuracy: 75.52517696959275\n",
      "y_pred mean :  -8.824605245268325\n",
      "Model accuracy: 75.16120711890638\n",
      "y_pred mean :  -9.460039493045844\n",
      "Model accuracy: 75.5438053477775\n",
      "y_pred mean :  -9.249933862128682\n",
      "Model accuracy: 75.17410368841888\n",
      "y_pred mean :  -9.89463783882654\n",
      "Model accuracy: 75.56243372596222\n",
      "y_pred mean :  -9.674995458897131\n",
      "Model accuracy: 75.18700025793139\n",
      "y_pred mean :  -10.328998179287302\n",
      "Model accuracy: 75.5667325824664\n",
      "y_pred mean :  -10.099818111703932\n",
      "Model accuracy: 75.21279339695641\n",
      "y_pred mean :  -10.763144814798046\n",
      "Model accuracy: 75.58392800848307\n",
      "y_pred mean :  -10.524426065230427\n",
      "Model accuracy: 75.23858653598143\n",
      "y_pred mean :  -11.197098825429471\n",
      "Model accuracy: 75.58965981715531\n",
      "y_pred mean :  -10.948840370309515\n",
      "Model accuracy: 75.22568996646892\n",
      "y_pred mean :  -11.630878589867187\n",
      "Model accuracy: 75.59539162582753\n",
      "y_pred mean :  -11.373079396259934\n",
      "Model accuracy: 75.22568996646892\n",
      "y_pred mean :  -12.064500206407612\n",
      "Model accuracy: 75.5996904823317\n",
      "y_pred mean :  -11.797159246549738\n",
      "Model accuracy: 75.23858653598143\n",
      "y_pred mean :  -12.497977837314341\n",
      "Model accuracy: 75.61115409967616\n",
      "y_pred mean :  -12.221094098930402\n",
      "Model accuracy: 75.23858653598143\n",
      "y_pred mean :  -12.931323992554569\n",
      "Model accuracy: 75.6197518126845\n",
      "y_pred mean :  -12.644896485894416\n",
      "Model accuracy: 75.22568996646892\n",
      "y_pred mean :  -13.36454976512635\n",
      "Model accuracy: 75.6226177170206\n",
      "y_pred mean :  -13.068577527502082\n",
      "Model accuracy: 75.25148310549393\n",
      "y_pred mean :  -13.79766502739222\n",
      "Model accuracy: 75.6226177170206\n",
      "y_pred mean :  -13.492147125844483\n",
      "Model accuracy: 75.26437967500645\n",
      "y_pred mean :  -14.230678595757693\n",
      "Model accuracy: 75.62691657352478\n",
      "y_pred mean :  -13.915614128353873\n",
      "Model accuracy: 75.26437967500645\n",
      "y_pred mean :  -14.663598369470748\n",
      "Model accuracy: 75.632648382197\n",
      "y_pred mean :  -14.338986465631818\n",
      "Model accuracy: 75.27727624451896\n",
      "y_pred mean :  -15.096431448131245\n",
      "Model accuracy: 75.63981314303729\n",
      "y_pred mean :  -14.762271268297019\n",
      "Model accuracy: 75.31596595305649\n",
      "y_pred mean :  -15.529184231586807\n",
      "Model accuracy: 75.64411199954145\n",
      "y_pred mean :  -15.18547496645836\n",
      "Model accuracy: 75.31596595305649\n",
      "y_pred mean :  -15.961862505184168\n",
      "Model accuracy: 75.64554495170951\n",
      "y_pred mean :  -15.608603374723987\n",
      "Model accuracy: 75.31596595305649\n",
      "y_pred mean :  -16.394471512790123\n",
      "Model accuracy: 75.65127676038173\n",
      "y_pred mean :  -16.03166176511316\n",
      "Model accuracy: 75.328862522569\n",
      "y_pred mean :  -16.827016019557934\n",
      "Model accuracy: 75.65414266471785\n",
      "y_pred mean :  -16.45465492980792\n",
      "Model accuracy: 75.328862522569\n",
      "y_pred mean :  -17.25950036606505\n",
      "Model accuracy: 75.65414266471785\n",
      "y_pred mean :  -16.877587235339263\n",
      "Model accuracy: 75.328862522569\n",
      "y_pred mean :  -17.691928515166005\n",
      "Model accuracy: 75.65414266471785\n",
      "y_pred mean :  -17.300462669526972\n",
      "Model accuracy: 75.3417590920815\n",
      "y_pred mean :  -18.12430409267612\n",
      "Model accuracy: 75.65127676038173\n",
      "y_pred mean :  -17.723284882269564\n",
      "Model accuracy: 75.3417590920815\n",
      "y_pred mean :  -18.55663042281514\n",
      "Model accuracy: 75.65557561688591\n",
      "y_pred mean :  -18.146057221099234\n",
      "Model accuracy: 75.3417590920815\n",
      "y_pred mean :  -18.988910559186245\n",
      "Model accuracy: 75.65700856905397\n",
      "y_pred mean :  -18.56878276226748\n",
      "Model accuracy: 75.35465566159401\n",
      "y_pred mean :  -19.421147311940274\n",
      "Model accuracy: 75.65700856905397\n",
      "y_pred mean :  -18.99146433800448\n",
      "Model accuracy: 75.36755223110653\n",
      "y_pred mean :  -19.853343271669935\n",
      "Model accuracy: 75.65700856905397\n",
      "y_pred mean :  -19.414104560493488\n",
      "Model accuracy: 75.38044880061904\n",
      "y_pred mean :  -20.285500830492612\n",
      "Model accuracy: 75.65844152122202\n",
      "y_pred mean :  -19.836705843017405\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -20.717622200707936\n",
      "Model accuracy: 75.65987447339008\n",
      "y_pred mean :  -20.259270418663657\n",
      "Model accuracy: 75.41913850915657\n",
      "y_pred mean :  -21.14970943135684\n",
      "Model accuracy: 75.6656062820623\n",
      "y_pred mean :  -20.681800356915364\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -21.581764422958724\n",
      "Model accuracy: 75.66703923423036\n",
      "y_pred mean :  -21.10429757840722\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -22.013788940661964\n",
      "Model accuracy: 75.67420399507064\n",
      "y_pred mean :  -21.526763868083513\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -22.44578462600795\n",
      "Model accuracy: 75.67420399507064\n",
      "y_pred mean :  -21.949200886960732\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -22.877753007480024\n",
      "Model accuracy: 75.67277104290258\n",
      "y_pred mean :  -22.371610182668277\n",
      "Model accuracy: 75.40624193964406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -23.309695509984365\n",
      "Model accuracy: 75.67133809073454\n",
      "y_pred mean :  -22.79399319891628\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -23.74161346338917\n",
      "Model accuracy: 75.67706989940676\n",
      "y_pred mean :  -23.21635128401877\n",
      "Model accuracy: 75.40624193964406\n",
      "y_pred mean :  -24.173508110231264\n",
      "Model accuracy: 75.67993580374286\n",
      "y_pred mean :  -23.638685698582567\n",
      "Model accuracy: 75.41913850915657\n",
      "y_pred mean :  -24.605380612684794\n",
      "Model accuracy: 75.68136875591092\n",
      "y_pred mean :  -24.06099762245788\n",
      "Model accuracy: 75.41913850915657\n",
      "y_pred mean :  -25.037232058874135\n",
      "Model accuracy: 75.67993580374286\n",
      "y_pred mean :  -24.483288161033652\n",
      "Model accuracy: 75.41913850915657\n",
      "y_pred mean :  -25.4690634686027\n",
      "Model accuracy: 75.68136875591092\n",
      "y_pred mean :  -24.90555835095002\n",
      "Model accuracy: 75.43203507866907\n",
      "y_pred mean :  -25.900875798560232\n",
      "Model accuracy: 75.67850285157482\n",
      "y_pred mean :  -25.327809165290887\n",
      "Model accuracy: 75.43203507866907\n",
      "y_pred mean :  -26.33266994706351\n",
      "Model accuracy: 75.68136875591092\n",
      "y_pred mean :  -25.75004151831204\n",
      "Model accuracy: 75.44493164818158\n",
      "y_pred mean :  -26.76444675837879\n",
      "Model accuracy: 75.68280170807898\n",
      "y_pred mean :  -26.17225626975317\n",
      "Model accuracy: 75.44493164818158\n",
      "y_pred mean :  -27.196207026668578\n",
      "Model accuracy: 75.6885335167512\n",
      "y_pred mean :  -26.594454228776506\n",
      "Model accuracy: 75.44493164818158\n",
      "y_pred mean :  -27.627951499600268\n",
      "Model accuracy: 75.68710056458315\n",
      "y_pred mean :  -27.016636157569614\n",
      "Model accuracy: 75.44493164818158\n",
      "y_pred mean :  -28.059680881650145\n",
      "Model accuracy: 75.68996646891927\n",
      "y_pred mean :  -27.438802774645776\n",
      "Model accuracy: 75.44493164818158\n",
      "y_pred mean :  -28.49139583713202\n",
      "Model accuracy: 75.69139942108733\n",
      "y_pred mean :  -27.86095475787115\n",
      "Model accuracy: 75.44493164818158\n",
      "y_pred mean :  -28.92309699297729\n",
      "Model accuracy: 75.69283237325538\n",
      "y_pred mean :  -28.283092747245252\n",
      "Model accuracy: 75.4578282176941\n",
      "y_pred mean :  -29.35478494128943\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -28.70521734745769\n",
      "Model accuracy: 75.4578282176941\n",
      "y_pred mean :  -29.78646024169415\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -29.12732913024225\n",
      "Model accuracy: 75.4707247872066\n",
      "y_pred mean :  -30.218123423503933\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -29.54942863654672\n",
      "Model accuracy: 75.4707247872066\n",
      "y_pred mean :  -30.6497749877136\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -29.971516378535085\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -31.081415408842222\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -30.393592841437183\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -31.513045136634688\n",
      "Model accuracy: 75.69426532542344\n",
      "y_pred mean :  -30.81565848525893\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -31.94466459763539\n",
      "Model accuracy: 75.69426532542344\n",
      "y_pred mean :  -31.237713746365532\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -32.37627419664488\n",
      "Model accuracy: 75.69426532542344\n",
      "y_pred mean :  -31.659759038948273\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -32.807874318069395\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -32.08179475638483\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -33.23946532717256\n",
      "Model accuracy: 75.69856418192761\n",
      "y_pred mean :  -32.50382127250204\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -33.671047571236855\n",
      "Model accuracy: 75.69856418192761\n",
      "y_pred mean :  -32.92583894274892\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -34.10262138064282\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -33.34784810528759\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -34.53418706987233\n",
      "Model accuracy: 75.69713122975955\n",
      "y_pred mean :  -33.769849082008456\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -34.96574493844201\n",
      "Model accuracy: 75.69713122975955\n",
      "y_pred mean :  -34.1918421794756\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -35.39729527177266\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -34.61382768980822\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -35.828838341999294\n",
      "Model accuracy: 75.69569827759149\n",
      "y_pred mean :  -35.035805891502676\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -36.26037440872674\n",
      "Model accuracy: 75.69713122975955\n",
      "y_pred mean :  -35.45777705019998\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -36.69190371973487\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -35.8797414194029\n",
      "Model accuracy: 75.49651792623162\n",
      "y_pred mean :  -37.12342651163703\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -36.30169924114589\n",
      "Model accuracy: 75.49651792623162\n",
      "y_pred mean :  -37.554943010495926\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -36.723650746622624\n",
      "Model accuracy: 75.49651792623162\n",
      "y_pred mean :  -37.98645343239915\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -37.14559615677265\n",
      "Model accuracy: 75.49651792623162\n",
      "y_pred mean :  -38.41795798399806\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -37.56753568283137\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -38.84945686301261\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -37.98946952684569\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -39.280950258704195\n",
      "Model accuracy: 75.69999713409567\n",
      "y_pred mean :  -38.41139788215726\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -39.71243835231912\n",
      "Model accuracy: 75.70286303843177\n",
      "y_pred mean :  -38.833320933856385\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -40.14392131750484\n",
      "Model accuracy: 75.70286303843177\n",
      "y_pred mean :  -39.255238859208156\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -40.57539932070054\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -39.677151828052715\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -41.00687252150445\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -40.099060003182\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -41.438341073018584\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -40.52096354069368\n",
      "Model accuracy: 75.48362135671911\n",
      "y_pred mean :  -41.86980512217354\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -40.94286259032468\n",
      "Model accuracy: 75.49651792623162\n",
      "y_pred mean :  -42.30126481003376\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -41.36475729576501\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -42.7327202720851\n",
      "Model accuracy: 75.70716189493595\n",
      "y_pred mean :  -41.786647794953645\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -43.16417163850589\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -42.20853422035745\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -43.595619034422185\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -42.63041669923421\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -44.02706258014866\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -43.05229535388084\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -44.45850239141587\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -43.47417030186783\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -44.889938579584864\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -43.896041656260664\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -45.32137125184989\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -44.317909525829144\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -45.752800511429825\n",
      "Model accuracy: 75.70716189493595\n",
      "y_pred mean :  -44.73977401524519\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -46.18422645774936\n",
      "Model accuracy: 75.70716189493595\n",
      "y_pred mean :  -45.16163522527001\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -46.61564918661032\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -45.583493252931355\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -47.047068790353705\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -46.0053481916911\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -47.47848535801336\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -46.42720013160429\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -47.90989897546123\n",
      "Model accuracy: 75.70286303843177\n",
      "y_pred mean :  -46.84904915946953\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -48.34130972554527\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -47.27089535897187\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -48.772717688220226\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -47.692738810818234\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -49.2041229406713\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -48.11457959286563\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -49.6355255574321\n",
      "Model accuracy: 75.70429599059983\n",
      "y_pred mean :  -48.53641778024342\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -50.06692561049618\n",
      "Model accuracy: 75.70572894276789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -48.95825344546891\n",
      "Model accuracy: 75.52231106525664\n",
      "y_pred mean :  -50.49832316942308\n",
      "Model accuracy: 75.70572894276789\n",
      "y_pred mean :  -49.38008665855744\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -50.92971830143916\n",
      "Model accuracy: 75.71002779927205\n",
      "y_pred mean :  -49.80191748712691\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -51.36111107153344\n",
      "Model accuracy: 75.71002779927205\n",
      "y_pred mean :  -50.22374599649724\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -51.79250154254867\n",
      "Model accuracy: 75.71146075144011\n",
      "y_pred mean :  -50.645572249784806\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -52.2238897752682\n",
      "Model accuracy: 75.71146075144011\n",
      "y_pred mean :  -51.067396307992695\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -52.65527582849813\n",
      "Model accuracy: 75.71146075144011\n",
      "y_pred mean :  -51.48921823009587\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -53.08665975914622\n",
      "Model accuracy: 75.71289370360817\n",
      "y_pred mean :  -51.91103807312312\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -53.51804162229662\n",
      "Model accuracy: 75.71289370360817\n",
      "y_pred mean :  -52.33285589223455\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -53.94942147128107\n",
      "Model accuracy: 75.71432665577623\n",
      "y_pred mean :  -52.754671740795594\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -54.38079935774705\n",
      "Model accuracy: 75.71575960794429\n",
      "y_pred mean :  -53.17648567044762\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -54.81217533172245\n",
      "Model accuracy: 75.71575960794429\n",
      "y_pred mean :  -53.59829773117516\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -55.24354944167755\n",
      "Model accuracy: 75.71719256011234\n",
      "y_pred mean :  -54.020107971370095\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -55.67492173458389\n",
      "Model accuracy: 75.71719256011234\n",
      "y_pred mean :  -54.441916437892864\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -56.10629225597076\n",
      "Model accuracy: 75.71719256011234\n",
      "y_pred mean :  -54.863723176130996\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -56.53766104997891\n",
      "Model accuracy: 75.71719256011234\n",
      "y_pred mean :  -55.285528230054894\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -56.96902815941202\n",
      "Model accuracy: 75.7186255122804\n",
      "y_pred mean :  -55.70733164227112\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -57.4003936257858\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -56.12913345407338\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -57.83175748937501\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -56.55093370549126\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -58.263119789258354\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -56.972732435336766\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -58.694480563361346\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -57.39452968124879\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -59.1258398484977\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -57.81632547973585\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -59.55719768040865\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -58.238119866217\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -59.9885540938004\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -58.659912875060506\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -60.41990912238058\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -59.0817045396216\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -60.851262798892755\n",
      "Model accuracy: 75.72005846444846\n",
      "y_pred mean :  -59.503494892278255\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -61.282615155149564\n",
      "Model accuracy: 75.72149141661652\n",
      "y_pred mean :  -59.9252839644654\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -61.713966222064606\n",
      "Model accuracy: 75.72149141661652\n",
      "y_pred mean :  -60.347071786708\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -62.145316029683\n",
      "Model accuracy: 75.72149141661652\n",
      "y_pred mean :  -60.768858388652575\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -62.576664607210645\n",
      "Model accuracy: 75.72149141661652\n",
      "y_pred mean :  -61.1906437990975\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -63.008011983042294\n",
      "Model accuracy: 75.72292436878458\n",
      "y_pred mean :  -61.61242804602205\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -63.43935818478863\n",
      "Model accuracy: 75.72292436878458\n",
      "y_pred mean :  -62.034211156614354\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -63.87070323930216\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -62.455993157298174\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -64.30204717270212\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -62.8777740737586\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -64.73339001039851\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -63.299553930966994\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -65.1647317771149\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -63.721332753204386\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -65.59607249691064\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -64.14311056408467\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -66.02741219320218\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -64.56488738657636\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -66.45875088878374\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -64.98666324302413\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -66.89008860584659\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -65.4084381551687\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -67.32142536599828\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -65.83021214416672\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -67.75276119028075\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -66.25198523060953\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -68.18409609918827\n",
      "Model accuracy: 75.72435732095262\n",
      "y_pred mean :  -66.67375743454166\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -68.61543011268373\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -67.09552877547785\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -69.04676325021572\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -67.51729927242059\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -69.47809553073367\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -67.93906894387607\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -69.90942697270354\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -68.36083780787014\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -70.34075759412194\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -68.78260588196338\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -70.77208741253062\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -69.20437318326607\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -71.20341644502989\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -69.62613972845206\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -71.63474470829186\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -70.047905533773\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -72.06607221857331\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -70.46967061507145\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -72.49739899172754\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -70.89143498779376\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -72.92872504321666\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -71.3131986670028\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -73.36005038812274\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -71.73496166738994\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -73.79137504115897\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -72.15672400328695\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -74.2226990166804\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -72.57848568867753\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -74.65402232869437\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -73.00024673720854\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -75.08534499087031\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -73.42200716220066\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -75.51666701654956\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -73.84376697665915\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -75.94798841875463\n",
      "Model accuracy: 75.72579027312068\n",
      "y_pred mean :  -74.26552619328412\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -76.37930921019858\n",
      "Model accuracy: 75.72722322528874\n",
      "y_pred mean :  -74.68728482448091\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -76.81062940329375\n",
      "Model accuracy: 75.72722322528874\n",
      "y_pred mean :  -75.10904288236985\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -77.24194901015993\n",
      "Model accuracy: 75.72722322528874\n",
      "y_pred mean :  -75.53080037879573\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -77.67326804263305\n",
      "Model accuracy: 75.72722322528874\n",
      "y_pred mean :  -75.95255732533762\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -78.10458651227302\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -76.37431373331793\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -78.53590443037156\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -76.79606961381194\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -78.96722180795969\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -77.21782497765633\n",
      "Model accuracy: 75.50941449574414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -79.3985386558152\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -77.63957983545863\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -79.82985498446958\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -78.06133419760539\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -80.26117080421515\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -78.48308807427132\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -80.69248612511173\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -78.90484147542763\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -81.12380095699311\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -79.32659441085033\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -81.55511530947335\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -79.74834689012867\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -81.98642919195319\n",
      "Model accuracy: 75.73008912962486\n",
      "y_pred mean :  -80.17009892267335\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -82.41774261362582\n",
      "Model accuracy: 75.7315220817929\n",
      "y_pred mean :  -80.59185051772447\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -82.84905558348278\n",
      "Model accuracy: 75.7315220817929\n",
      "y_pred mean :  -81.0136016843595\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -83.28036811032\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -81.43535243150141\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -83.71168020274278\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -81.85710276792582\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -84.14299186917161\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -82.27885270226881\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -84.57430311784721\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -82.70060224303396\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -85.00561395683573\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -83.12235139859932\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -85.4369243940334\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -83.54410017722401\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -85.86823443717175\n",
      "Model accuracy: 75.73295503396096\n",
      "y_pred mean :  -83.96584858705452\n",
      "Model accuracy: 75.50941449574414\n",
      "y_pred mean :  -86.29954409382186\n",
      "Model accuracy: 75.7315220817929\n",
      "y_pred mean :  -84.38759663613034\n",
      "Model accuracy: 75.50941449574414\n",
      "Training with config: {'method': <function reg_logistic_regression at 0x7fd8263ebf80>, 'max_iters': 2000, 'lambda_': 1e-08, 'start_degree': -3, 'end_degree': 8, 'include_half': True, 'include_cross_terms': True}\n",
      "Model training time=1949.991 seconds\n",
      "Test for datasplit : 2 and k 0\n",
      "y_pred mean :  -0.0023277055630070444\n",
      "Model accuracy: 71.5108199324995\n",
      "y_pred mean :  -0.0008017379347845638\n",
      "Model accuracy: 71.37184832241414\n",
      "y_pred mean :  -0.206949129027587\n",
      "Model accuracy: 72.6821520746476\n",
      "y_pred mean :  -0.1415836867071851\n",
      "Model accuracy: 72.76156442326781\n",
      "y_pred mean :  -0.3975718465485302\n",
      "Model accuracy: 73.10568460062207\n",
      "y_pred mean :  -0.28853390533112444\n",
      "Model accuracy: 73.0196545562835\n",
      "y_pred mean :  -0.5850370904777364\n",
      "Model accuracy: 73.31965676218208\n",
      "y_pred mean :  -0.4350191536337004\n",
      "Model accuracy: 73.13877307921382\n",
      "y_pred mean :  -0.7710989127170323\n",
      "Model accuracy: 73.41230450223898\n",
      "y_pred mean :  -0.5811658786357221\n",
      "Model accuracy: 73.27774468929918\n",
      "y_pred mean :  -0.9563816331572453\n",
      "Model accuracy: 73.5049522422959\n",
      "y_pred mean :  -0.7270859937096888\n",
      "Model accuracy: 73.3174508636093\n",
      "y_pred mean :  -1.1411722136102849\n",
      "Model accuracy: 73.60642357664395\n",
      "y_pred mean :  -0.8728456554667201\n",
      "Model accuracy: 73.4365693865396\n",
      "y_pred mean :  -1.3256279167165983\n",
      "Model accuracy: 73.6395120552357\n",
      "y_pred mean :  -1.0184741812835267\n",
      "Model accuracy: 73.41671629938456\n",
      "y_pred mean :  -1.509844125061092\n",
      "Model accuracy: 73.67039463525467\n",
      "y_pred mean :  -1.1639894356700575\n",
      "Model accuracy: 73.49612864800477\n",
      "y_pred mean :  -1.6938811909826572\n",
      "Model accuracy: 73.69907131670085\n",
      "y_pred mean :  -1.3094083820038729\n",
      "Model accuracy: 73.51598173515981\n",
      "y_pred mean :  -1.8777792084086906\n",
      "Model accuracy: 73.72995389671983\n",
      "y_pred mean :  -1.4547455528683026\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -2.0615661076594414\n",
      "Model accuracy: 73.75642467959324\n",
      "y_pred mean :  -1.6000125711759743\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -2.2452621369777392\n",
      "Model accuracy: 73.77848366532106\n",
      "y_pred mean :  -1.7452186821777962\n",
      "Model accuracy: 73.51598173515981\n",
      "y_pred mean :  -2.428882471549815\n",
      "Model accuracy: 73.78068956389386\n",
      "y_pred mean :  -1.8903713606691395\n",
      "Model accuracy: 73.51598173515981\n",
      "y_pred mean :  -2.612438807586286\n",
      "Model accuracy: 73.80936624534004\n",
      "y_pred mean :  -2.035476772720767\n",
      "Model accuracy: 73.45642247369466\n",
      "y_pred mean :  -2.7959403759996615\n",
      "Model accuracy: 73.8424547239318\n",
      "y_pred mean :  -2.180540099083567\n",
      "Model accuracy: 73.45642247369466\n",
      "y_pred mean :  -2.9793946090936343\n",
      "Model accuracy: 73.8424547239318\n",
      "y_pred mean :  -2.3255657603965694\n",
      "Model accuracy: 73.45642247369466\n",
      "y_pred mean :  -3.16280759220877\n",
      "Model accuracy: 73.85127831822292\n",
      "y_pred mean :  -2.470557576594145\n",
      "Model accuracy: 73.47627556084971\n",
      "y_pred mean :  -3.3461843780301614\n",
      "Model accuracy: 73.85789601394129\n",
      "y_pred mean :  -2.6155188822414055\n",
      "Model accuracy: 73.47627556084971\n",
      "y_pred mean :  -3.5295292108677185\n",
      "Model accuracy: 73.86671960823242\n",
      "y_pred mean :  -2.7604526119146486\n",
      "Model accuracy: 73.47627556084971\n",
      "y_pred mean :  -3.7128456905166654\n",
      "Model accuracy: 73.86671960823242\n",
      "y_pred mean :  -2.9053613648691416\n",
      "Model accuracy: 73.49612864800477\n",
      "y_pred mean :  -3.8961368946612223\n",
      "Model accuracy: 73.87554320252355\n",
      "y_pred mean :  -3.0502474551433387\n",
      "Model accuracy: 73.53583482231487\n",
      "y_pred mean :  -4.0794054722155035\n",
      "Model accuracy: 73.86451370965963\n",
      "y_pred mean :  -3.1951129512534613\n",
      "Model accuracy: 73.53583482231487\n",
      "y_pred mean :  -4.262653715855289\n",
      "Model accuracy: 73.87113140537798\n",
      "y_pred mean :  -3.3399597083208574\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -4.445883619338395\n",
      "Model accuracy: 73.87333730395076\n",
      "y_pred mean :  -3.4847893945996167\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -4.629096923480659\n",
      "Model accuracy: 73.87774910109633\n",
      "y_pred mean :  -3.629603513781629\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -4.812295153509881\n",
      "Model accuracy: 73.88216089824189\n",
      "y_pred mean :  -3.774403424054911\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -4.995479649751004\n",
      "Model accuracy: 73.89319039110582\n",
      "y_pred mean :  -3.9191903546152353\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -5.1786515930712165\n",
      "Model accuracy: 73.90421988396973\n",
      "y_pred mean :  -4.063965420139997\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -5.361812026149361\n",
      "Model accuracy: 73.90421988396973\n",
      "y_pred mean :  -4.208729633598061\n",
      "Model accuracy: 73.55568790946992\n",
      "y_pred mean :  -5.544961871377469\n",
      "Model accuracy: 73.90642578254251\n",
      "y_pred mean :  -4.353483917671859\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -5.728101946018463\n",
      "Model accuracy: 73.91304347826087\n",
      "y_pred mean :  -4.49822911499487\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -5.911232975110924\n",
      "Model accuracy: 73.91524937683366\n",
      "y_pred mean :  -4.642965997350265\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -6.094355602514309\n",
      "Model accuracy: 73.9086316811153\n",
      "y_pred mean :  -4.787695273929116\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -6.277470400416203\n",
      "Model accuracy: 73.9086316811153\n",
      "y_pred mean :  -4.932417598705486\n",
      "Model accuracy: 73.57554099662498\n",
      "y_pred mean :  -6.46057787756962\n",
      "Model accuracy: 73.91745527540644\n",
      "y_pred mean :  -5.077133576949667\n",
      "Model accuracy: 73.59539408378002\n",
      "y_pred mean :  -6.643678486488051\n",
      "Model accuracy: 73.91524937683366\n",
      "y_pred mean :  -5.221843770870046\n",
      "Model accuracy: 73.61524717093508\n",
      "y_pred mean :  -6.826772629794184\n",
      "Model accuracy: 73.91304347826087\n",
      "y_pred mean :  -5.366548704351149\n",
      "Model accuracy: 73.63510025809013\n",
      "y_pred mean :  -7.009860665891161\n",
      "Model accuracy: 73.91524937683366\n",
      "y_pred mean :  -5.511248866744512\n",
      "Model accuracy: 73.63510025809013\n",
      "y_pred mean :  -7.192942914099518\n",
      "Model accuracy: 73.91524937683366\n",
      "y_pred mean :  -5.6559447156752665\n",
      "Model accuracy: 73.65495334524519\n",
      "y_pred mean :  -7.376019659375496\n",
      "Model accuracy: 73.91524937683366\n",
      "y_pred mean :  -5.800636678855706\n",
      "Model accuracy: 73.65495334524519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -7.559091156695507\n",
      "Model accuracy: 73.91966117397922\n",
      "y_pred mean :  -5.945325154949209\n",
      "Model accuracy: 73.65495334524519\n",
      "y_pred mean :  -7.742157635157193\n",
      "Model accuracy: 73.91966117397922\n",
      "y_pred mean :  -6.090010513600884\n",
      "Model accuracy: 73.67480643240023\n",
      "y_pred mean :  -7.925219301811749\n",
      "Model accuracy: 73.92407297112479\n",
      "y_pred mean :  -6.2346930948340455\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -8.108276345209749\n",
      "Model accuracy: 73.92627886969757\n",
      "y_pred mean :  -6.379373208087591\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -8.291328938618687\n",
      "Model accuracy: 73.92848476827035\n",
      "y_pred mean :  -6.524051131217188\n",
      "Model accuracy: 73.67480643240023\n",
      "y_pred mean :  -8.474377242860152\n",
      "Model accuracy: 73.92627886969757\n",
      "y_pred mean :  -6.6687271097864\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -8.657421408720264\n",
      "Model accuracy: 73.92848476827035\n",
      "y_pred mean :  -6.813401356924755\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -8.840461578906611\n",
      "Model accuracy: 73.92848476827035\n",
      "y_pred mean :  -6.958074053934994\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -9.023497889554184\n",
      "Model accuracy: 73.93069066684313\n",
      "y_pred mean :  -7.10274535171178\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -9.206530471312881\n",
      "Model accuracy: 73.93289656541592\n",
      "y_pred mean :  -7.247415372913779\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -9.389559450074788\n",
      "Model accuracy: 73.93510246398871\n",
      "y_pred mean :  -7.392084214736135\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -9.57258494741453\n",
      "Model accuracy: 73.93510246398871\n",
      "y_pred mean :  -7.5367519520736055\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -9.755607080820276\n",
      "Model accuracy: 73.93510246398871\n",
      "y_pred mean :  -7.681418640850565\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -9.938625963787668\n",
      "Model accuracy: 73.93510246398871\n",
      "y_pred mean :  -7.826084321314375\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -10.121641705837071\n",
      "Model accuracy: 73.93289656541592\n",
      "y_pred mean :  -7.9707490211312875\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -10.304654412499943\n",
      "Model accuracy: 73.93289656541592\n",
      "y_pred mean :  -8.115412758175367\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -10.487664185305734\n",
      "Model accuracy: 73.93510246398871\n",
      "y_pred mean :  -8.260075542950817\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -10.67067112178787\n",
      "Model accuracy: 73.9373083625615\n",
      "y_pred mean :  -8.404737380629468\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -10.853675315517753\n",
      "Model accuracy: 73.9373083625615\n",
      "y_pred mean :  -8.549398272715615\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -11.036676856168983\n",
      "Model accuracy: 73.9373083625615\n",
      "y_pred mean :  -8.694058218370348\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -11.219675829609397\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -8.838717215437567\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -11.40267231801647\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -8.983375261217768\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -11.585666400010645\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -9.128032353034378\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -11.76865815080099\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -9.272688488633602\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -11.95164764233835\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -9.41734366645359\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -12.134634943471783\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -9.561997885793144\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -12.317620120104692\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -9.706651146904523\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -12.500603235348327\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -9.851303451030468\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -12.683584349670612\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -9.995954800401009\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -12.866563521038973\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -10.140605198202229\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -13.04954080505637\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -10.28525464852623\n",
      "Model accuracy: 73.69465951955529\n",
      "y_pred mean :  -13.232516255090108\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -10.429903156309429\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -13.415489922393157\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -10.574550727264159\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -13.598461856218115\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -10.719197367807531\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -13.781432103923942\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -10.863843084990128\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -13.964400711075667\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -11.008487886426321\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -14.147367721537622\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -11.153131780227723\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -14.330333177560322\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -11.297774774940182\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -14.513297119861624\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -11.442416879485089\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -14.69625958770243\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -11.587058103105067\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -14.879220618957325\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -11.731698455313959\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -15.062180250180617\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -11.876337945851297\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -15.24513851666801\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.020976584640797\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -15.428095452514384\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.165614381752865\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -15.611051090667937\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.310251347370817\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -15.794005462980886\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.45488749176047\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -15.97695860025715\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.599522825242909\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -16.15991053229715\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.74415735817021\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -16.342861287940057\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -12.88879110090379\n",
      "Model accuracy: 73.71451260671034\n",
      "y_pred mean :  -16.525810895103472\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -13.033424063795126\n",
      "Model accuracy: 73.7343656938654\n",
      "y_pred mean :  -16.708759380821043\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -13.178056257168778\n",
      "Model accuracy: 73.7343656938654\n",
      "y_pred mean :  -16.891706771277995\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -13.32268769130737\n",
      "Model accuracy: 73.7343656938654\n",
      "y_pred mean :  -17.074653091844578\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -13.467318376438248\n",
      "Model accuracy: 73.7343656938654\n",
      "y_pred mean :  -17.257598367108063\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -13.611948322722018\n",
      "Model accuracy: 73.7343656938654\n",
      "y_pred mean :  -17.44054262090278\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -13.756577540242244\n",
      "Model accuracy: 73.7343656938654\n",
      "y_pred mean :  -17.62348587633886\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -13.901206038996696\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -17.806428155829437\n",
      "Model accuracy: 73.93951426113428\n",
      "y_pred mean :  -14.04583382888964\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -17.989369481116633\n",
      "Model accuracy: 73.94172015970706\n",
      "y_pred mean :  -14.190460919725291\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -18.172309873296264\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -14.335087321202172\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -18.35524935284134\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -14.479713042908257\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -18.538187939624585\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -14.624338094316972\n",
      "Model accuracy: 73.75421878102046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -18.721125652939932\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -14.76896248478388\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -18.90406251152301\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -14.913586223543899\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -19.08699853357079\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -15.058209319709075\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -19.269933736760397\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -15.202831782266948\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -19.452868138267107\n",
      "Model accuracy: 73.94392605827984\n",
      "y_pred mean :  -15.347453620079168\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -19.635801754781614\n",
      "Model accuracy: 73.94613195685262\n",
      "y_pred mean :  -15.492074841880674\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -19.818734602526554\n",
      "Model accuracy: 73.94613195685262\n",
      "y_pred mean :  -15.636695456279076\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -20.00166669727242\n",
      "Model accuracy: 73.94613195685262\n",
      "y_pred mean :  -15.781315471754404\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -20.184598054352815\n",
      "Model accuracy: 73.94613195685262\n",
      "y_pred mean :  -15.92593489665915\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -20.36752868867906\n",
      "Model accuracy: 73.94613195685262\n",
      "y_pred mean :  -16.07055373921845\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -20.550458614754316\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -16.215172007530594\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -20.73338784668705\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -16.359789709567615\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -20.916316398204117\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -16.50440685317607\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -21.09924428266319\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -16.649023446078036\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -21.28217151306491\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -16.793639495872114\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -21.46509810206435\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -16.93825501003459\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -21.648024061982294\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -17.082869995920742\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -21.830949404815897\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -17.227484460766103\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -22.013874142249122\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -17.372098411687926\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -22.196798285662624\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -17.516711855686623\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -22.379721846143493\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -17.66132479964727\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -22.562644834494385\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -17.805937250341156\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -22.745567261242538\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -17.95054921442733\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -22.92848913664841\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -18.095160698454297\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -23.111410470713896\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -18.239771708861525\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -23.29433127319051\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -18.384382251981226\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -23.477251553586964\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -18.528992334039877\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -23.66017132117669\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -18.67360196115995\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -23.843090585005044\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -18.81821113936152\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -24.02600935389633\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -18.962819874564012\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -24.208927636460334\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.10742817258773\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -24.391845441099054\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.25203603915566\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -24.57476277601268\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.396643479894912\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -24.757679649205908\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.54125050033856\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -24.940596068493523\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.685857105927063\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -25.123512041506267\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.83046330201005\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -25.30642757569611\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -19.97506909384775\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -25.489342678341565\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.119674486612638\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -25.672257356552816\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.26427948539098\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -25.855171617276543\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.408884095184344\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -26.038085467300746\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.55348832091115\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -26.220998913259287\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.69809216740814\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -26.40391196163634\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.842695639431845\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -26.586824618770617\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -20.98729874166005\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -26.769736890859626\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -21.131901478693226\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -26.95264878396355\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -21.276503855055932\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -27.13556030400918\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -21.421105875198204\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -27.3184714567937\n",
      "Model accuracy: 73.94833785542541\n",
      "y_pred mean :  -21.565707543496963\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -27.5013822479882\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -21.71030886425729\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -27.684292683141273\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -21.854909841713802\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -27.867202767682368\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -21.999510480031947\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -28.05011250692506\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -22.14411078330928\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -28.23302190607021\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -22.288710755576673\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -28.415930970209065\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -22.43331040079966\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -28.598839704326156\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -22.5779097228795\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -28.781748113302307\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -22.72250872565456\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -28.96465620191726\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -22.867107412901316\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -29.147563974852496\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -23.01170578833563\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -29.330471436693742\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -23.156303855613796\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -29.513378591933524\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -23.30090161833368\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -29.696285444973633\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -23.445499080035816\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -29.879192000127492\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -23.590096244204496\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -30.062098261622403\n",
      "Model accuracy: 73.95054375399819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -23.734693114268776\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -30.24500423360179\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -23.879289693603514\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -30.427909920127384\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.02388598553044\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -30.610815325181235\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.168481993319084\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -30.793720452667785\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.313077720187746\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -30.97662530641578\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.457673169304478\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -31.159529890180238\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.602268343788054\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -31.342434207644192\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.74686324670882\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -31.52533826242054\n",
      "Model accuracy: 73.95054375399819\n",
      "y_pred mean :  -24.89145788108962\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -31.708242058053766\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -25.03605224990674\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -31.89114559802158\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -25.18064635609068\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -32.07404888573655\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -25.32524020252703\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -32.25695192454771\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -25.469833792057354\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -32.439854717742044\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -25.61442712747996\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -32.622757268545996\n",
      "Model accuracy: 73.95274965257097\n",
      "y_pred mean :  -25.759020211550677\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -32.80565958012691\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -25.903613046983747\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -32.98856165559444\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.04820563645248\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -33.1714634980018\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.19279798259\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -33.35436511034721\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.3373900879901\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -33.537266495575196\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.48198195520794\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -33.720167656577644\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.62657358676061\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -33.90306859619516\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.771164985128003\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -34.08596931721825\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -26.915756152753456\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -34.268869822388346\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -27.060347092044356\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -34.451770114398926\n",
      "Model accuracy: 73.95495555114375\n",
      "y_pred mean :  -27.20493780537278\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -34.634670195896724\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -27.349528295076286\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -34.8175700694826\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -27.49411856345837\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -35.000469737712706\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -27.638708612789255\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -35.18336920309929\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -27.783298445306293\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -35.36626846811181\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -27.927888063214695\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -35.54916753517781\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -28.072477468688096\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -35.73206640668385\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -28.217066663869147\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -35.91496508497626\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -28.361655650869913\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -36.09786357236217\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -28.506244431772615\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -36.280761871110265\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -28.65083300863009\n",
      "Model accuracy: 73.75421878102046\n",
      "y_pred mean :  -36.46365998345158\n",
      "Model accuracy: 73.95716144971654\n",
      "y_pred mean :  -28.79542138346631\n",
      "Model accuracy: 73.75421878102046\n",
      "Training with config: {'method': <function reg_logistic_regression at 0x7fd8263ebf80>, 'max_iters': 2000, 'lambda_': 1e-08, 'start_degree': -3, 'end_degree': 8, 'include_half': True, 'include_cross_terms': True}\n",
      "Model training time=2716.255 seconds\n",
      "Test for datasplit : 3 and k 0\n",
      "y_pred mean :  -0.001808633082130123\n",
      "Model accuracy: 65.29783393501805\n",
      "y_pred mean :  -0.0016122471010593215\n",
      "Model accuracy: 64.4404332129964\n",
      "y_pred mean :  -0.17770530494259046\n",
      "Model accuracy: 68.22101885278781\n",
      "y_pred mean :  -0.16071816399186792\n",
      "Model accuracy: 67.59927797833934\n",
      "y_pred mean :  -0.34635309885404875\n",
      "Model accuracy: 70.0962695547533\n",
      "y_pred mean :  -0.31588973268385817\n",
      "Model accuracy: 69.85559566787003\n",
      "y_pred mean :  -0.5101510000920665\n",
      "Model accuracy: 71.39991977537103\n",
      "y_pred mean :  -0.4677612339658367\n",
      "Model accuracy: 71.29963898916968\n",
      "y_pred mean :  -0.6701767443113764\n",
      "Model accuracy: 72.09687123947052\n",
      "y_pred mean :  -0.6166699865922178\n",
      "Model accuracy: 71.79602888086643\n",
      "y_pred mean :  -0.8270881216470886\n",
      "Model accuracy: 72.79883674288007\n",
      "y_pred mean :  -0.762908606434439\n",
      "Model accuracy: 72.47292418772564\n",
      "y_pred mean :  -0.981365791180837\n",
      "Model accuracy: 73.42559165663859\n",
      "y_pred mean :  -0.9067615632042104\n",
      "Model accuracy: 72.87906137184116\n",
      "y_pred mean :  -1.1333903312914915\n",
      "Model accuracy: 73.87184115523466\n",
      "y_pred mean :  -1.0484983418835898\n",
      "Model accuracy: 73.19494584837545\n",
      "y_pred mean :  -1.283474259303508\n",
      "Model accuracy: 74.1977537103891\n",
      "y_pred mean :  -1.18836675928598\n",
      "Model accuracy: 73.78158844765343\n",
      "y_pred mean :  -1.4318788339062312\n",
      "Model accuracy: 74.64400320898515\n",
      "y_pred mean :  -1.3265896200332066\n",
      "Model accuracy: 74.23285198555956\n",
      "y_pred mean :  -1.5788247394459152\n",
      "Model accuracy: 74.92478941034898\n",
      "y_pred mean :  -1.4633646897011294\n",
      "Model accuracy: 74.54873646209386\n",
      "y_pred mean :  -1.7244998336304715\n",
      "Model accuracy: 75.2055756117128\n",
      "y_pred mean :  -1.5988668727605357\n",
      "Model accuracy: 74.81949458483754\n",
      "y_pred mean :  -1.8690649058328954\n",
      "Model accuracy: 75.33594063377457\n",
      "y_pred mean :  -1.7332504963912152\n",
      "Model accuracy: 74.86462093862816\n",
      "y_pred mean :  -2.01265787869267\n",
      "Model accuracy: 75.50140393100682\n",
      "y_pred mean :  -1.8666507169186901\n",
      "Model accuracy: 75.22563176895306\n",
      "y_pred mean :  -2.155397089837626\n",
      "Model accuracy: 75.65182511030886\n",
      "y_pred mean :  -1.9991848385807538\n",
      "Model accuracy: 75.36101083032491\n",
      "y_pred mean :  -2.2973841143997507\n",
      "Model accuracy: 75.74709185720016\n",
      "y_pred mean :  -2.1309541280438555\n",
      "Model accuracy: 75.40613718411552\n",
      "y_pred mean :  -2.438706253075227\n",
      "Model accuracy: 75.87745687926193\n",
      "y_pred mean :  -2.262045900197919\n",
      "Model accuracy: 75.54151624548736\n",
      "y_pred mean :  -2.5794386951334083\n",
      "Model accuracy: 76.01283594063378\n",
      "y_pred mean :  -2.3925355367956342\n",
      "Model accuracy: 75.63176895306859\n",
      "y_pred mean :  -2.7196463718652057\n",
      "Model accuracy: 76.09807460890494\n",
      "y_pred mean :  -2.5224882848729493\n",
      "Model accuracy: 75.58664259927798\n",
      "y_pred mean :  -2.859385529438836\n",
      "Model accuracy: 76.14821500200561\n",
      "y_pred mean :  -2.6519608067359157\n",
      "Model accuracy: 75.49638989169675\n",
      "y_pred mean :  -2.998705053603741\n",
      "Model accuracy: 76.22342559165664\n",
      "y_pred mean :  -2.7810024954017734\n",
      "Model accuracy: 75.72202166064982\n",
      "y_pred mean :  -3.1376475786154\n",
      "Model accuracy: 76.30365022061773\n",
      "y_pred mean :  -2.909656577576701\n",
      "Model accuracy: 75.72202166064982\n",
      "y_pred mean :  -3.2762504121116742\n",
      "Model accuracy: 76.37384677095868\n",
      "y_pred mean :  -3.0379610283860567\n",
      "Model accuracy: 75.76714801444044\n",
      "y_pred mean :  -3.4145463061375176\n",
      "Model accuracy: 76.42900120336944\n",
      "y_pred mean :  -3.1659493249414665\n",
      "Model accuracy: 75.72202166064982\n",
      "y_pred mean :  -3.5525641015306886\n",
      "Model accuracy: 76.52426795026074\n",
      "y_pred mean :  -3.2936510675129047\n",
      "Model accuracy: 75.76714801444044\n",
      "y_pred mean :  -3.6903292687880116\n",
      "Model accuracy: 76.59446450060169\n",
      "y_pred mean :  -3.4210924954958095\n",
      "Model accuracy: 75.90252707581227\n",
      "y_pred mean :  -3.8278643642160723\n",
      "Model accuracy: 76.61452065784195\n",
      "y_pred mean :  -3.5482969209851896\n",
      "Model accuracy: 75.9476534296029\n",
      "y_pred mean :  -3.9651894163602743\n",
      "Model accuracy: 76.64460489370236\n",
      "y_pred mean :  -3.675285097436481\n",
      "Model accuracy: 75.9476534296029\n",
      "y_pred mean :  -4.102322254673731\n",
      "Model accuracy: 76.6395908543923\n",
      "y_pred mean :  -3.8020755361453435\n",
      "Model accuracy: 76.03790613718411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -4.239278790068031\n",
      "Model accuracy: 76.65964701163257\n",
      "y_pred mean :  -3.9286847797403786\n",
      "Model accuracy: 76.12815884476534\n",
      "y_pred mean :  -4.376073255202695\n",
      "Model accuracy: 76.66967509025271\n",
      "y_pred mean :  -4.055127639504584\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -4.512718410960952\n",
      "Model accuracy: 76.69975932611311\n",
      "y_pred mean :  -4.181417401811625\n",
      "Model accuracy: 76.17328519855596\n",
      "y_pred mean :  -4.6492257244219\n",
      "Model accuracy: 76.69474528680306\n",
      "y_pred mean :  -4.307566007966608\n",
      "Model accuracy: 76.17328519855596\n",
      "y_pred mean :  -4.785605522711934\n",
      "Model accuracy: 76.71480144404332\n",
      "y_pred mean :  -4.433584211051535\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -4.921867126361865\n",
      "Model accuracy: 76.72482952266346\n",
      "y_pred mean :  -4.559481712856332\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -5.058018965181865\n",
      "Model accuracy: 76.77496991576415\n",
      "y_pred mean :  -4.685267283554949\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -5.194068679168644\n",
      "Model accuracy: 76.80004011231448\n",
      "y_pred mean :  -4.8109488664275615\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -5.3300232065562945\n",
      "Model accuracy: 76.82009626955475\n",
      "y_pred mean :  -4.93653366961825\n",
      "Model accuracy: 76.35379061371842\n",
      "y_pred mean :  -5.465888860794727\n",
      "Model accuracy: 76.83513838748496\n",
      "y_pred mean :  -5.062028246645668\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -5.601671397971466\n",
      "Model accuracy: 76.83513838748496\n",
      "y_pred mean :  -5.187438567147416\n",
      "Model accuracy: 76.26353790613719\n",
      "y_pred mean :  -5.737376075971041\n",
      "Model accuracy: 76.85018050541517\n",
      "y_pred mean :  -5.3127700791338315\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -5.873007706481209\n",
      "Model accuracy: 76.88026474127557\n",
      "y_pred mean :  -5.438027763850278\n",
      "Model accuracy: 76.26353790613719\n",
      "y_pred mean :  -6.008570700799618\n",
      "Model accuracy: 76.89530685920577\n",
      "y_pred mean :  -5.563216184195585\n",
      "Model accuracy: 76.26353790613719\n",
      "y_pred mean :  -6.144069110261688\n",
      "Model accuracy: 76.90032089851584\n",
      "y_pred mean :  -5.688339527514093\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -6.2795066619972415\n",
      "Model accuracy: 76.92037705575612\n",
      "y_pred mean :  -5.813401643467836\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -6.414886790625526\n",
      "Model accuracy: 76.91536301644605\n",
      "y_pred mean :  -5.938406077599921\n",
      "Model accuracy: 76.26353790613719\n",
      "y_pred mean :  -6.550212666413753\n",
      "Model accuracy: 76.91536301644605\n",
      "y_pred mean :  -6.06335610111857\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -6.685487220351003\n",
      "Model accuracy: 76.93040513437626\n",
      "y_pred mean :  -6.1882547373611105\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -6.820713166525507\n",
      "Model accuracy: 76.93541917368633\n",
      "y_pred mean :  -6.313104785336781\n",
      "Model accuracy: 76.17328519855596\n",
      "y_pred mean :  -6.955893022138314\n",
      "Model accuracy: 76.93541917368633\n",
      "y_pred mean :  -6.43790884069553\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -7.091029125438156\n",
      "Model accuracy: 76.95547533092659\n",
      "y_pred mean :  -6.562669314424993\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -7.226123651821356\n",
      "Model accuracy: 76.95046129161652\n",
      "y_pred mean :  -6.6873884495397\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -7.361178628305326\n",
      "Model accuracy: 76.9404332129964\n",
      "y_pred mean :  -6.812068335993405\n",
      "Model accuracy: 76.21841155234657\n",
      "y_pred mean :  -7.496195946554183\n",
      "Model accuracy: 76.93541917368633\n",
      "y_pred mean :  -6.936710924017086\n",
      "Model accuracy: 76.26353790613719\n",
      "y_pred mean :  -7.631177374610356\n",
      "Model accuracy: 76.93541917368633\n",
      "y_pred mean :  -7.061318036060976\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -7.766124567465273\n",
      "Model accuracy: 76.96550340954673\n",
      "y_pred mean :  -7.185891377498042\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -7.901039076585538\n",
      "Model accuracy: 76.985559566787\n",
      "y_pred mean :  -7.310432546228373\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.035922358497587\n",
      "Model accuracy: 77.00561572402728\n",
      "y_pred mean :  -7.434943041308467\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.170775782522796\n",
      "Model accuracy: 77.01062976333735\n",
      "y_pred mean :  -7.559424270715653\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.305600637746302\n",
      "Model accuracy: 77.00561572402728\n",
      "y_pred mean :  -7.683877558345894\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.440398139295437\n",
      "Model accuracy: 77.01564380264742\n",
      "y_pred mean :  -7.808304150332461\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.57516943399745\n",
      "Model accuracy: 77.03569995988768\n",
      "y_pred mean :  -7.932705220763243\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.709915605480512\n",
      "Model accuracy: 77.03569995988768\n",
      "y_pred mean :  -8.057081876865498\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.844637678776852\n",
      "Model accuracy: 77.05074207781789\n",
      "y_pred mean :  -8.181435163718932\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -8.979336624481904\n",
      "Model accuracy: 77.05074207781789\n",
      "y_pred mean :  -8.305766068550657\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -9.114013362518527\n",
      "Model accuracy: 77.06077015643802\n",
      "y_pred mean :  -8.430075524658845\n",
      "Model accuracy: 76.3086642599278\n",
      "y_pred mean :  -9.248668765550557\n",
      "Model accuracy: 77.06077015643802\n",
      "y_pred mean :  -8.554364415006006\n",
      "Model accuracy: 76.35379061371842\n",
      "y_pred mean :  -9.383303662085726\n",
      "Model accuracy: 77.05575611712796\n",
      "y_pred mean :  -8.678633575517681\n",
      "Model accuracy: 76.35379061371842\n",
      "y_pred mean :  -9.517918839303395\n",
      "Model accuracy: 77.06077015643802\n",
      "y_pred mean :  -8.802883798117467\n",
      "Model accuracy: 76.39891696750902\n",
      "y_pred mean :  -9.652515045638443\n",
      "Model accuracy: 77.06077015643802\n",
      "y_pred mean :  -8.927115833525251\n",
      "Model accuracy: 76.39891696750902\n",
      "y_pred mean :  -9.787092993149328\n",
      "Model accuracy: 77.0657841957481\n",
      "y_pred mean :  -9.051330393842363\n",
      "Model accuracy: 76.39891696750902\n",
      "y_pred mean :  -9.921653359694396\n",
      "Model accuracy: 77.07581227436823\n",
      "y_pred mean :  -9.175528154943908\n",
      "Model accuracy: 76.39891696750902\n",
      "y_pred mean :  -10.056196790937582\n",
      "Model accuracy: 77.07079823505816\n",
      "y_pred mean :  -9.299709758696167\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.190723902202055\n",
      "Model accuracy: 77.08584035298837\n",
      "y_pred mean :  -9.423875815014913\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.325235280187721\n",
      "Model accuracy: 77.09085439229844\n",
      "y_pred mean :  -9.548026903778364\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.459731484566516\n",
      "Model accuracy: 77.09586843160851\n",
      "y_pred mean :  -9.672163576607206\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.594213049467378\n",
      "Model accuracy: 77.09085439229844\n",
      "y_pred mean :  -9.796286358522433\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.728680484861496\n",
      "Model accuracy: 77.08584035298837\n",
      "y_pred mean :  -9.920395749490968\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.86313427785702\n",
      "Model accuracy: 77.09085439229844\n",
      "y_pred mean :  -10.044492225867915\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -10.997574893910945\n",
      "Model accuracy: 77.0808263136783\n",
      "y_pred mean :  -10.168576241743198\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -11.13200277796541\n",
      "Model accuracy: 77.08584035298837\n",
      "y_pred mean :  -10.29264823020004\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -11.26641835551439\n",
      "Model accuracy: 77.09586843160851\n",
      "y_pred mean :  -10.41670860449171\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -11.400822033606355\n",
      "Model accuracy: 77.09586843160851\n",
      "y_pred mean :  -10.5407577591426\n",
      "Model accuracy: 76.48916967509025\n",
      "y_pred mean :  -11.535214201787642\n",
      "Model accuracy: 77.09586843160851\n",
      "y_pred mean :  -10.664796070979099\n",
      "Model accuracy: 76.53429602888086\n",
      "y_pred mean :  -11.669595232990934\n",
      "Model accuracy: 77.10088247091858\n",
      "y_pred mean :  -10.788823900095316\n",
      "Model accuracy: 76.53429602888086\n",
      "y_pred mean :  -11.803965484372705\n",
      "Model accuracy: 77.10589651022865\n",
      "y_pred mean :  -10.912841590758255\n",
      "Model accuracy: 76.53429602888086\n",
      "y_pred mean :  -11.938325298103118\n",
      "Model accuracy: 77.12093862815884\n",
      "y_pred mean :  -11.03684947225667\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -12.072675002111557\n",
      "Model accuracy: 77.11592458884877\n",
      "y_pred mean :  -11.16084785969754\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -12.207014910790784\n",
      "Model accuracy: 77.11592458884877\n",
      "y_pred mean :  -11.284837054753842\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -12.34134532566221\n",
      "Model accuracy: 77.13096670677898\n",
      "y_pred mean :  -11.408817346366808\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -12.47566653600476\n",
      "Model accuracy: 77.12595266746891\n",
      "y_pred mean :  -11.532789011405848\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -12.609978819449662\n",
      "Model accuracy: 77.14099478539912\n",
      "y_pred mean :  -11.656752315288994\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -12.74428244254309\n",
      "Model accuracy: 77.13598074608905\n",
      "y_pred mean :  -11.78070751256646\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -12.878577661278628\n",
      "Model accuracy: 77.14099478539912\n",
      "y_pred mean :  -11.90465484746977\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.012864721601302\n",
      "Model accuracy: 77.13096670677898\n",
      "y_pred mean :  -12.028594554428704\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.147143859884881\n",
      "Model accuracy: 77.14600882470918\n",
      "y_pred mean :  -12.152526858558215\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.28141530338395\n",
      "Model accuracy: 77.16606498194946\n",
      "y_pred mean :  -12.276451976117233\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.415679270662096\n",
      "Model accuracy: 77.17107902125953\n",
      "y_pred mean :  -12.400370114941094\n",
      "Model accuracy: 76.62454873646209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred mean :  -13.549935971997744\n",
      "Model accuracy: 77.1760930605696\n",
      "y_pred mean :  -12.524281474849406\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.68418560976878\n",
      "Model accuracy: 77.1760930605696\n",
      "y_pred mean :  -12.648186248030877\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.818428378817092\n",
      "Model accuracy: 77.17107902125953\n",
      "y_pred mean :  -12.77208461940646\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -13.952664466794234\n",
      "Model accuracy: 77.1760930605696\n",
      "y_pred mean :  -12.895976766972293\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.086894054489264\n",
      "Model accuracy: 77.1760930605696\n",
      "y_pred mean :  -13.019862862123665\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.221117316139619\n",
      "Model accuracy: 77.18110709987967\n",
      "y_pred mean :  -13.143743069961134\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.355334419726063\n",
      "Model accuracy: 77.1760930605696\n",
      "y_pred mean :  -13.267617549579935\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.48954552725255\n",
      "Model accuracy: 77.1760930605696\n",
      "y_pred mean :  -13.39148645434375\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.62375079501172\n",
      "Model accuracy: 77.18110709987967\n",
      "y_pred mean :  -13.5153499321436\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.757950373837055\n",
      "Model accuracy: 77.18612113918974\n",
      "y_pred mean :  -13.639208125643098\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -14.892144409342093\n",
      "Model accuracy: 77.19614921780986\n",
      "y_pred mean :  -13.763061172510493\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.026333042147638\n",
      "Model accuracy: 77.20116325711993\n",
      "y_pred mean :  -13.886909205638604\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.160516408097502\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -14.01075235335314\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.294694638463525\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -14.13459073961036\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.428867860140166\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -14.258424484184335\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.563036195829595\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -14.382253702844764\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.697199764217535\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -14.506078507525734\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.831358680140383\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -14.6298990064859\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -15.96551305474421\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -14.753715304460709\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -16.099662995635896\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -14.877527502807004\n",
      "Model accuracy: 76.66967509025271\n",
      "y_pred mean :  -16.233808607027008\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.001335699640595\n",
      "Model accuracy: 76.71480144404332\n",
      "y_pred mean :  -16.367949989870585\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.125139989966947\n",
      "Model accuracy: 76.66967509025271\n",
      "y_pred mean :  -16.502087241991386\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.248940465805594\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -16.636220458209984\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.372737216308655\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -16.77034973046077\n",
      "Model accuracy: 77.2212194143602\n",
      "y_pred mean :  -15.496530327873497\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -16.90447514790446\n",
      "Model accuracy: 77.2212194143602\n",
      "y_pred mean :  -15.620319884250138\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.038596797035282\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.744105966643593\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.172714761783148\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.867888653811443\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.30682912361101\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -15.991668022156846\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.440939961607814\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -16.115444145817303\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.57504735257709\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -16.239217096749393\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.70915137112141\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -16.362986944809467\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.843252089723308\n",
      "Model accuracy: 77.20116325711993\n",
      "y_pred mean :  -16.48675375783111\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -17.977349578822167\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -16.610517601698707\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.111443906887935\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -16.734278540418064\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.245535140491558\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -16.858036636183858\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.379623344372057\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -16.981791949444\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.513708581500957\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -17.10554453896139\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.64779091314371\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -17.229294461872932\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.781870398918635\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -17.353041773746124\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -18.915947096853174\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -17.476786528633124\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.050021063437853\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -17.60052877912266\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.184092353677922\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -17.724268576389683\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.318161021142878\n",
      "Model accuracy: 77.21119133574007\n",
      "y_pred mean :  -17.84800597024312\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.4522271180139\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -17.971741009171474\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.586290695129325\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -18.09547374038673\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.720351802028276\n",
      "Model accuracy: 77.20116325711993\n",
      "y_pred mean :  -18.21920420986639\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.85441048699254\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -18.34293246239387\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -19.988466797086776\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -18.466658541597294\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.12252077819704\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -18.59038248998671\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.256572475067838\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -18.714104348989853\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.390621931337805\n",
      "Model accuracy: 77.20617729643\n",
      "y_pred mean :  -18.837824158986596\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.524669189573814\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -18.96154195934194\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.658714291303994\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -19.08525778843788\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.79275727704926\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -19.20897168370389\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -20.92679818635381\n",
      "Model accuracy: 77.21620537505014\n",
      "y_pred mean :  -19.332683681646404\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.060837057814446\n",
      "Model accuracy: 77.2212194143602\n",
      "y_pred mean :  -19.45639381787714\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.19487392910869\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -19.580102127140282\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.328908837022034\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -19.703808643338792\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.462941817474047\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -19.827513399559663\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.59697290554359\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -19.951216428098274\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.731002135493135\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -20.074917760481828\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.86502954079221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -20.198617427492067\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -21.999055154139963\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -20.322315459186957\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -22.13307900748694\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -20.44601188492178\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -22.267101132056187\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -20.569706733369436\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -22.401121558363553\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -20.693400032540037\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -22.535140316237214\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -20.817091809799667\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -22.669157434836773\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -20.940782091888845\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -22.803172942671367\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -21.064470904939878\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -22.9371868676175\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.188158274494036\n",
      "Model accuracy: 76.57942238267148\n",
      "y_pred mean :  -23.071199236936064\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.31184422551794\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -23.20521007728892\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.435528782419407\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -23.339219414754865\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.55921196906283\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -23.473227274845\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.682893808783884\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -23.607233682517865\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.806574324404032\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -23.741238662193776\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -21.93025353824424\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -23.875242237768926\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -22.053931472138448\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.009244432628932\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -22.17760814744654\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.143245269661975\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -22.301283585066876\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.277244771271558\n",
      "Model accuracy: 77.2212194143602\n",
      "y_pred mean :  -22.424957805448404\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.411242959388858\n",
      "Model accuracy: 77.2212194143602\n",
      "y_pred mean :  -22.548630828602512\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.545239855484628\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -22.672302674114295\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.679235480580875\n",
      "Model accuracy: 77.22623345367028\n",
      "y_pred mean :  -22.795973361153663\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.813229855262026\n",
      "Model accuracy: 77.23124749298034\n",
      "y_pred mean :  -22.91964290848595\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -24.9472229996859\n",
      "Model accuracy: 77.23626153229041\n",
      "y_pred mean :  -23.043311334482336\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.081214933594232\n",
      "Model accuracy: 77.23626153229041\n",
      "y_pred mean :  -23.166978657129786\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.215205676322977\n",
      "Model accuracy: 77.23626153229041\n",
      "y_pred mean :  -23.29064489404085\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.349195246812197\n",
      "Model accuracy: 77.24127557160048\n",
      "y_pred mean :  -23.414310062462953\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.48318366361585\n",
      "Model accuracy: 77.24127557160048\n",
      "y_pred mean :  -23.5379741792877\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.61717094491105\n",
      "Model accuracy: 77.24127557160048\n",
      "y_pred mean :  -23.661637261059575\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.75115710850722\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -23.78529932398457\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -25.885142171854934\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -23.908960383938545\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.019126152054607\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -24.032620456475357\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.153109065864633\n",
      "Model accuracy: 77.25130365022062\n",
      "y_pred mean :  -24.15627955683452\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.287090929709677\n",
      "Model accuracy: 77.25130365022062\n",
      "y_pred mean :  -24.27993769994899\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.421071759688502\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -24.40359490045252\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.555051571581558\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -24.52725117268673\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.68903038085858\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -24.65090653070822\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.82300820268569\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -24.774560988295267\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -26.956985051932488\n",
      "Model accuracy: 77.24628961091055\n",
      "y_pred mean :  -24.898214558954365\n",
      "Model accuracy: 76.62454873646209\n",
      "y_pred mean :  -27.090960943178917\n",
      "Model accuracy: 77.25130365022062\n",
      "y_pred mean :  -25.021867255926654\n",
      "Model accuracy: 76.62454873646209\n"
     ]
    }
   ],
   "source": [
    "train_acc_list_all, test_acc_list_all = run_model_split_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1897722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[73.90651586427785, 77.84672872251693, 79.34919205062334, 80.0754011944083, 80.48577052680746, 80.72932305741834, 80.85054326671782, 80.9561939078504, 81.02180851655379, 81.06629299703066, 81.0940957973287, 81.11522592555522, 81.13524394176982, 81.15748618200826, 81.18195264627053, 81.19863432644937, 81.21420389461626, 81.23310979881894, 81.24423091893816, 81.24979147899776, 81.2564641510693, 81.26313682314083, 81.26424893515275, 81.26313682314083, 81.26869738320043, 81.2720337192362, 81.27981850331966, 81.2820427273435, 81.28871539941503, 81.28649117539119, 81.28649117539119, 81.28982751142695, 81.29872440752233, 81.29983651953425, 81.30317285557001, 81.30317285557001, 81.30650919160578, 81.3076213036177, 81.3076213036177, 81.30984552764154, 81.30984552764154, 81.30984552764154, 81.31206975166539, 81.31318186367731, 81.31429397568922, 81.31429397568922, 81.31540608770115, 81.31429397568922, 81.31651819971307, 81.31985453574885, 81.31874242373692, 81.31985453574885, 81.32207875977268, 81.32430298379653, 81.32541509580845, 81.32541509580845, 81.32541509580845, 81.32875143184421, 81.32875143184421, 81.32763931983229, 81.32875143184421, 81.32875143184421, 81.32875143184421, 81.32986354385613, 81.33097565586806, 81.33208776787998, 81.33208776787998, 81.33431199190383, 81.33431199190383, 81.33542410391574, 81.33431199190383, 81.33653621592767, 81.33764832793959, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33987255196344, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33876043995151, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33987255196344, 81.33987255196344, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33876043995151, 81.33876043995151, 81.33987255196344, 81.33876043995151, 81.33876043995151, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.34098466397536, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33987255196344, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33876043995151, 81.33764832793959, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33653621592767, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959, 81.33764832793959], [69.44802682486458, 72.28383916544865, 73.38291347834809, 74.01484538446107, 74.32293010059324, 74.60665462986846, 74.79150545954776, 74.95772791104233, 75.0580345628063, 75.1569082624022, 75.22855587080504, 75.30880119221621, 75.36468632677041, 75.39621127446766, 75.404808987476, 75.43919983950936, 75.46499297853438, 75.49365202189551, 75.50511563923996, 75.51084744791218, 75.52517696959275, 75.5438053477775, 75.56243372596222, 75.5667325824664, 75.58392800848307, 75.58965981715531, 75.59539162582753, 75.5996904823317, 75.61115409967616, 75.6197518126845, 75.6226177170206, 75.6226177170206, 75.62691657352478, 75.632648382197, 75.63981314303729, 75.64411199954145, 75.64554495170951, 75.65127676038173, 75.65414266471785, 75.65414266471785, 75.65414266471785, 75.65127676038173, 75.65557561688591, 75.65700856905397, 75.65700856905397, 75.65700856905397, 75.65844152122202, 75.65987447339008, 75.6656062820623, 75.66703923423036, 75.67420399507064, 75.67420399507064, 75.67277104290258, 75.67133809073454, 75.67706989940676, 75.67993580374286, 75.68136875591092, 75.67993580374286, 75.68136875591092, 75.67850285157482, 75.68136875591092, 75.68280170807898, 75.6885335167512, 75.68710056458315, 75.68996646891927, 75.69139942108733, 75.69283237325538, 75.69569827759149, 75.69569827759149, 75.69569827759149, 75.69569827759149, 75.69569827759149, 75.69426532542344, 75.69426532542344, 75.69426532542344, 75.69569827759149, 75.69856418192761, 75.69856418192761, 75.69569827759149, 75.69713122975955, 75.69713122975955, 75.69569827759149, 75.69569827759149, 75.69713122975955, 75.69999713409567, 75.69999713409567, 75.69999713409567, 75.69999713409567, 75.69999713409567, 75.69999713409567, 75.69999713409567, 75.70286303843177, 75.70286303843177, 75.70429599059983, 75.70429599059983, 75.70429599059983, 75.70429599059983, 75.70429599059983, 75.70716189493595, 75.70572894276789, 75.70572894276789, 75.70429599059983, 75.70572894276789, 75.70572894276789, 75.70572894276789, 75.70716189493595, 75.70716189493595, 75.70572894276789, 75.70429599059983, 75.70429599059983, 75.70286303843177, 75.70429599059983, 75.70429599059983, 75.70429599059983, 75.70429599059983, 75.70572894276789, 75.70572894276789, 75.71002779927205, 75.71002779927205, 75.71146075144011, 75.71146075144011, 75.71146075144011, 75.71289370360817, 75.71289370360817, 75.71432665577623, 75.71575960794429, 75.71575960794429, 75.71719256011234, 75.71719256011234, 75.71719256011234, 75.71719256011234, 75.7186255122804, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72005846444846, 75.72149141661652, 75.72149141661652, 75.72149141661652, 75.72149141661652, 75.72292436878458, 75.72292436878458, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72435732095262, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72579027312068, 75.72722322528874, 75.72722322528874, 75.72722322528874, 75.72722322528874, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.73008912962486, 75.7315220817929, 75.7315220817929, 75.73295503396096, 75.73295503396096, 75.73295503396096, 75.73295503396096, 75.73295503396096, 75.73295503396096, 75.73295503396096, 75.7315220817929], [71.5108199324995, 72.6821520746476, 73.10568460062207, 73.31965676218208, 73.41230450223898, 73.5049522422959, 73.60642357664395, 73.6395120552357, 73.67039463525467, 73.69907131670085, 73.72995389671983, 73.75642467959324, 73.77848366532106, 73.78068956389386, 73.80936624534004, 73.8424547239318, 73.8424547239318, 73.85127831822292, 73.85789601394129, 73.86671960823242, 73.86671960823242, 73.87554320252355, 73.86451370965963, 73.87113140537798, 73.87333730395076, 73.87774910109633, 73.88216089824189, 73.89319039110582, 73.90421988396973, 73.90421988396973, 73.90642578254251, 73.91304347826087, 73.91524937683366, 73.9086316811153, 73.9086316811153, 73.91745527540644, 73.91524937683366, 73.91304347826087, 73.91524937683366, 73.91524937683366, 73.91524937683366, 73.91966117397922, 73.91966117397922, 73.92407297112479, 73.92627886969757, 73.92848476827035, 73.92627886969757, 73.92848476827035, 73.92848476827035, 73.93069066684313, 73.93289656541592, 73.93510246398871, 73.93510246398871, 73.93510246398871, 73.93510246398871, 73.93289656541592, 73.93289656541592, 73.93510246398871, 73.9373083625615, 73.9373083625615, 73.9373083625615, 73.93951426113428, 73.93951426113428, 73.94172015970706, 73.94172015970706, 73.94172015970706, 73.94172015970706, 73.94172015970706, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94172015970706, 73.94172015970706, 73.94172015970706, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.93951426113428, 73.94172015970706, 73.93951426113428, 73.93951426113428, 73.94172015970706, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94392605827984, 73.94613195685262, 73.94613195685262, 73.94613195685262, 73.94613195685262, 73.94613195685262, 73.94833785542541, 73.94833785542541, 73.95054375399819, 73.95054375399819, 73.95274965257097, 73.95274965257097, 73.95274965257097, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.94833785542541, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95054375399819, 73.95274965257097, 73.95274965257097, 73.95274965257097, 73.95274965257097, 73.95274965257097, 73.95274965257097, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95495555114375, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654, 73.95716144971654], [65.29783393501805, 68.22101885278781, 70.0962695547533, 71.39991977537103, 72.09687123947052, 72.79883674288007, 73.42559165663859, 73.87184115523466, 74.1977537103891, 74.64400320898515, 74.92478941034898, 75.2055756117128, 75.33594063377457, 75.50140393100682, 75.65182511030886, 75.74709185720016, 75.87745687926193, 76.01283594063378, 76.09807460890494, 76.14821500200561, 76.22342559165664, 76.30365022061773, 76.37384677095868, 76.42900120336944, 76.52426795026074, 76.59446450060169, 76.61452065784195, 76.64460489370236, 76.6395908543923, 76.65964701163257, 76.66967509025271, 76.69975932611311, 76.69474528680306, 76.71480144404332, 76.72482952266346, 76.77496991576415, 76.80004011231448, 76.82009626955475, 76.83513838748496, 76.83513838748496, 76.85018050541517, 76.88026474127557, 76.89530685920577, 76.90032089851584, 76.92037705575612, 76.91536301644605, 76.91536301644605, 76.93040513437626, 76.93541917368633, 76.93541917368633, 76.95547533092659, 76.95046129161652, 76.9404332129964, 76.93541917368633, 76.93541917368633, 76.96550340954673, 76.985559566787, 77.00561572402728, 77.01062976333735, 77.00561572402728, 77.01564380264742, 77.03569995988768, 77.03569995988768, 77.05074207781789, 77.05074207781789, 77.06077015643802, 77.06077015643802, 77.05575611712796, 77.06077015643802, 77.06077015643802, 77.0657841957481, 77.07581227436823, 77.07079823505816, 77.08584035298837, 77.09085439229844, 77.09586843160851, 77.09085439229844, 77.08584035298837, 77.09085439229844, 77.0808263136783, 77.08584035298837, 77.09586843160851, 77.09586843160851, 77.09586843160851, 77.10088247091858, 77.10589651022865, 77.12093862815884, 77.11592458884877, 77.11592458884877, 77.13096670677898, 77.12595266746891, 77.14099478539912, 77.13598074608905, 77.14099478539912, 77.13096670677898, 77.14600882470918, 77.16606498194946, 77.17107902125953, 77.1760930605696, 77.1760930605696, 77.17107902125953, 77.1760930605696, 77.1760930605696, 77.18110709987967, 77.1760930605696, 77.1760930605696, 77.18110709987967, 77.18612113918974, 77.19614921780986, 77.20116325711993, 77.20617729643, 77.20617729643, 77.21119133574007, 77.21119133574007, 77.20617729643, 77.21119133574007, 77.21119133574007, 77.21119133574007, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.2212194143602, 77.2212194143602, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.20617729643, 77.20116325711993, 77.21119133574007, 77.20617729643, 77.21119133574007, 77.21119133574007, 77.21119133574007, 77.21119133574007, 77.20617729643, 77.20617729643, 77.21119133574007, 77.21119133574007, 77.21119133574007, 77.20617729643, 77.20617729643, 77.20116325711993, 77.20617729643, 77.20617729643, 77.20617729643, 77.20617729643, 77.20617729643, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.21620537505014, 77.2212194143602, 77.22623345367028, 77.22623345367028, 77.22623345367028, 77.23124749298034, 77.23124749298034, 77.23124749298034, 77.22623345367028, 77.23124749298034, 77.23124749298034, 77.22623345367028, 77.22623345367028, 77.22623345367028, 77.22623345367028, 77.23124749298034, 77.23124749298034, 77.23124749298034, 77.23124749298034, 77.23124749298034, 77.23124749298034, 77.23124749298034, 77.22623345367028, 77.22623345367028, 77.22623345367028, 77.2212194143602, 77.2212194143602, 77.22623345367028, 77.22623345367028, 77.23124749298034, 77.23626153229041, 77.23626153229041, 77.23626153229041, 77.24127557160048, 77.24127557160048, 77.24127557160048, 77.24628961091055, 77.24628961091055, 77.24628961091055, 77.25130365022062, 77.25130365022062, 77.24628961091055, 77.24628961091055, 77.24628961091055, 77.24628961091055, 77.24628961091055, 77.25130365022062]] [[73.61625462916625, 77.63987588829947, 79.23130817735962, 79.70173155840256, 80.1621459313382, 80.4724251826644, 80.69262336102493, 80.81273145831248, 80.91282153938545, 80.97287558802923, 80.99289360424382, 81.01291162045841, 81.0529476528876, 81.07296566910219, 81.13301971774597, 81.15303773396056, 81.17305575017515, 81.18306475828246, 81.18306475828246, 81.20308277449705, 81.21309178260434, 81.22310079071164, 81.22310079071164, 81.23310979881894, 81.24311880692623, 81.24311880692623, 81.25312781503354, 81.25312781503354, 81.26313682314083, 81.26313682314083, 81.25312781503354, 81.25312781503354, 81.26313682314083, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.29316384746272, 81.29316384746272, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.26313682314083, 81.26313682314083, 81.26313682314083, 81.26313682314083, 81.26313682314083, 81.27314583124813, 81.27314583124813, 81.27314583124813, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.27314583124813, 81.27314583124813, 81.27314583124813, 81.27314583124813, 81.27314583124813, 81.27314583124813, 81.28315483935542, 81.28315483935542, 81.28315483935542, 81.29316384746272, 81.29316384746272, 81.29316384746272, 81.29316384746272, 81.29316384746272, 81.29316384746272, 81.29316384746272, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.30317285557001, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.3231908717846, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731, 81.31318186367731], [69.26747485168946, 72.42713438225432, 73.42017023471756, 73.91023987619293, 74.4003095176683, 74.63244776889347, 74.74851689450607, 74.98065514573123, 75.04513799329378, 75.01934485426877, 75.09672427134382, 75.12251741036884, 75.17410368841888, 75.17410368841888, 75.22568996646892, 75.21279339695641, 75.17410368841888, 75.1998968274439, 75.17410368841888, 75.16120711890638, 75.16120711890638, 75.17410368841888, 75.18700025793139, 75.21279339695641, 75.23858653598143, 75.22568996646892, 75.22568996646892, 75.23858653598143, 75.23858653598143, 75.22568996646892, 75.25148310549393, 75.26437967500645, 75.26437967500645, 75.27727624451896, 75.31596595305649, 75.31596595305649, 75.31596595305649, 75.328862522569, 75.328862522569, 75.328862522569, 75.3417590920815, 75.3417590920815, 75.3417590920815, 75.35465566159401, 75.36755223110653, 75.38044880061904, 75.40624193964406, 75.41913850915657, 75.40624193964406, 75.40624193964406, 75.40624193964406, 75.40624193964406, 75.40624193964406, 75.40624193964406, 75.40624193964406, 75.41913850915657, 75.41913850915657, 75.41913850915657, 75.43203507866907, 75.43203507866907, 75.44493164818158, 75.44493164818158, 75.44493164818158, 75.44493164818158, 75.44493164818158, 75.44493164818158, 75.4578282176941, 75.4578282176941, 75.4707247872066, 75.4707247872066, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.49651792623162, 75.49651792623162, 75.49651792623162, 75.49651792623162, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.48362135671911, 75.49651792623162, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.52231106525664, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414, 75.50941449574414], [71.37184832241414, 72.76156442326781, 73.0196545562835, 73.13877307921382, 73.27774468929918, 73.3174508636093, 73.4365693865396, 73.41671629938456, 73.49612864800477, 73.51598173515981, 73.57554099662498, 73.57554099662498, 73.51598173515981, 73.51598173515981, 73.45642247369466, 73.45642247369466, 73.45642247369466, 73.47627556084971, 73.47627556084971, 73.47627556084971, 73.49612864800477, 73.53583482231487, 73.53583482231487, 73.55568790946992, 73.55568790946992, 73.55568790946992, 73.55568790946992, 73.55568790946992, 73.55568790946992, 73.55568790946992, 73.57554099662498, 73.57554099662498, 73.57554099662498, 73.57554099662498, 73.57554099662498, 73.59539408378002, 73.61524717093508, 73.63510025809013, 73.63510025809013, 73.65495334524519, 73.65495334524519, 73.65495334524519, 73.67480643240023, 73.69465951955529, 73.69465951955529, 73.67480643240023, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.69465951955529, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.71451260671034, 73.7343656938654, 73.7343656938654, 73.7343656938654, 73.7343656938654, 73.7343656938654, 73.7343656938654, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046, 73.75421878102046], [64.4404332129964, 67.59927797833934, 69.85559566787003, 71.29963898916968, 71.79602888086643, 72.47292418772564, 72.87906137184116, 73.19494584837545, 73.78158844765343, 74.23285198555956, 74.54873646209386, 74.81949458483754, 74.86462093862816, 75.22563176895306, 75.36101083032491, 75.40613718411552, 75.54151624548736, 75.63176895306859, 75.58664259927798, 75.49638989169675, 75.72202166064982, 75.72202166064982, 75.76714801444044, 75.72202166064982, 75.76714801444044, 75.90252707581227, 75.9476534296029, 75.9476534296029, 76.03790613718411, 76.12815884476534, 76.21841155234657, 76.17328519855596, 76.17328519855596, 76.21841155234657, 76.21841155234657, 76.21841155234657, 76.21841155234657, 76.35379061371842, 76.3086642599278, 76.26353790613719, 76.3086642599278, 76.26353790613719, 76.26353790613719, 76.21841155234657, 76.3086642599278, 76.26353790613719, 76.21841155234657, 76.21841155234657, 76.17328519855596, 76.21841155234657, 76.21841155234657, 76.21841155234657, 76.21841155234657, 76.26353790613719, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.3086642599278, 76.35379061371842, 76.35379061371842, 76.39891696750902, 76.39891696750902, 76.39891696750902, 76.39891696750902, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.48916967509025, 76.53429602888086, 76.53429602888086, 76.53429602888086, 76.57942238267148, 76.57942238267148, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.66967509025271, 76.71480144404332, 76.66967509025271, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.57942238267148, 76.57942238267148, 76.57942238267148, 76.57942238267148, 76.57942238267148, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209, 76.62454873646209]]\n"
     ]
    }
   ],
   "source": [
    "print(train_acc_list_all, test_acc_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2d7b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X, Xt, ids = load_csv_data('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05dbae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list, y_list, _ = subdivide_data(X, y)\n",
    "train_acc = (np.array(train_acc_list_all[0]) * X_list[0].shape[0] \n",
    "             + np.array(train_acc_list_all[1]) * X_list[1].shape[0]\n",
    "             + np.array(train_acc_list_all[2]) * X_list[2].shape[0]\n",
    "             + np.array(train_acc_list_all[3]) * X_list[3].shape[0]) / X.shape[0]\n",
    "test_acc = (np.array(test_acc_list_all[0]) * X_list[0].shape[0] \n",
    "             + np.array(test_acc_list_all[1]) * X_list[1].shape[0]\n",
    "             + np.array(test_acc_list_all[2]) * X_list[2].shape[0]\n",
    "             + np.array(test_acc_list_all[3]) * X_list[3].shape[0]) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b7dbbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(test_acc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "047d3815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot lines\n",
    "x = np.arange(0, train_acc.shape[0])\n",
    "plt.plot(x, train_acc, label = \"train acc\")\n",
    "plt.plot(x, test_acc, label = \"test acc\")\n",
    "plt.xlabel('iterations (/100)')\n",
    "plt.ylabel('% accuracy')\n",
    "#plt.plot(x, accuracy[2], label = \"line 3\")\n",
    "plt.legend()\n",
    "plt.savefig('../figs/accuracy_iterations_20000.png', bbox_inches='tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d38129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe471275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     1.0\n",
       "1    -1.0\n",
       "2    -1.0\n",
       "3    -1.0\n",
       "4    -1.0\n",
       "...   ...\n",
       "1995  1.0\n",
       "1996 -1.0\n",
       "1997 -1.0\n",
       "1998  1.0\n",
       "1999 -1.0\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_range = [0, 2000]\n",
    "X_sample = tX[sample_range[0] : sample_range[1]]\n",
    "y_sample = y[sample_range[0] : sample_range[1]]\n",
    "ids_sample = ids[sample_range[0] : sample_range[1]]\n",
    "pd.DataFrame(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c904a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>...</th>\n",
       "      <th>1750</th>\n",
       "      <th>1751</th>\n",
       "      <th>1752</th>\n",
       "      <th>1753</th>\n",
       "      <th>1754</th>\n",
       "      <th>1755</th>\n",
       "      <th>1756</th>\n",
       "      <th>1757</th>\n",
       "      <th>1758</th>\n",
       "      <th>1759</th>\n",
       "      <th>1760</th>\n",
       "      <th>1761</th>\n",
       "      <th>1762</th>\n",
       "      <th>1763</th>\n",
       "      <th>1764</th>\n",
       "      <th>1765</th>\n",
       "      <th>1766</th>\n",
       "      <th>1767</th>\n",
       "      <th>1768</th>\n",
       "      <th>1769</th>\n",
       "      <th>1770</th>\n",
       "      <th>1771</th>\n",
       "      <th>1772</th>\n",
       "      <th>1773</th>\n",
       "      <th>1774</th>\n",
       "      <th>1775</th>\n",
       "      <th>1776</th>\n",
       "      <th>1777</th>\n",
       "      <th>1778</th>\n",
       "      <th>1779</th>\n",
       "      <th>1780</th>\n",
       "      <th>1781</th>\n",
       "      <th>1782</th>\n",
       "      <th>1783</th>\n",
       "      <th>1784</th>\n",
       "      <th>1785</th>\n",
       "      <th>1786</th>\n",
       "      <th>1787</th>\n",
       "      <th>1788</th>\n",
       "      <th>1789</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>1792</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>1795</th>\n",
       "      <th>1796</th>\n",
       "      <th>1797</th>\n",
       "      <th>1798</th>\n",
       "      <th>1799</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>1809</th>\n",
       "      <th>1810</th>\n",
       "      <th>1811</th>\n",
       "      <th>1812</th>\n",
       "      <th>1813</th>\n",
       "      <th>1814</th>\n",
       "      <th>1815</th>\n",
       "      <th>1816</th>\n",
       "      <th>1817</th>\n",
       "      <th>1818</th>\n",
       "      <th>1819</th>\n",
       "      <th>1820</th>\n",
       "      <th>1821</th>\n",
       "      <th>1822</th>\n",
       "      <th>1823</th>\n",
       "      <th>1824</th>\n",
       "      <th>1825</th>\n",
       "      <th>1826</th>\n",
       "      <th>1827</th>\n",
       "      <th>1828</th>\n",
       "      <th>1829</th>\n",
       "      <th>1830</th>\n",
       "      <th>1831</th>\n",
       "      <th>1832</th>\n",
       "      <th>1833</th>\n",
       "      <th>1834</th>\n",
       "      <th>1835</th>\n",
       "      <th>1836</th>\n",
       "      <th>1837</th>\n",
       "      <th>1838</th>\n",
       "      <th>1839</th>\n",
       "      <th>1840</th>\n",
       "      <th>1841</th>\n",
       "      <th>1842</th>\n",
       "      <th>1843</th>\n",
       "      <th>1844</th>\n",
       "      <th>1845</th>\n",
       "      <th>1846</th>\n",
       "      <th>1847</th>\n",
       "      <th>1848</th>\n",
       "      <th>1849</th>\n",
       "      <th>1850</th>\n",
       "      <th>1851</th>\n",
       "      <th>1852</th>\n",
       "      <th>1853</th>\n",
       "      <th>1854</th>\n",
       "      <th>1855</th>\n",
       "      <th>1856</th>\n",
       "      <th>1857</th>\n",
       "      <th>1858</th>\n",
       "      <th>1859</th>\n",
       "      <th>1860</th>\n",
       "      <th>1861</th>\n",
       "      <th>1862</th>\n",
       "      <th>1863</th>\n",
       "      <th>1864</th>\n",
       "      <th>1865</th>\n",
       "      <th>1866</th>\n",
       "      <th>1867</th>\n",
       "      <th>1868</th>\n",
       "      <th>1869</th>\n",
       "      <th>1870</th>\n",
       "      <th>1871</th>\n",
       "      <th>1872</th>\n",
       "      <th>1873</th>\n",
       "      <th>1874</th>\n",
       "      <th>1875</th>\n",
       "      <th>1876</th>\n",
       "      <th>1877</th>\n",
       "      <th>1878</th>\n",
       "      <th>1879</th>\n",
       "      <th>1880</th>\n",
       "      <th>1881</th>\n",
       "      <th>1882</th>\n",
       "      <th>1883</th>\n",
       "      <th>1884</th>\n",
       "      <th>1885</th>\n",
       "      <th>1886</th>\n",
       "      <th>1887</th>\n",
       "      <th>1888</th>\n",
       "      <th>1889</th>\n",
       "      <th>1890</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "      <th>1899</th>\n",
       "      <th>1900</th>\n",
       "      <th>1901</th>\n",
       "      <th>1902</th>\n",
       "      <th>1903</th>\n",
       "      <th>1904</th>\n",
       "      <th>1905</th>\n",
       "      <th>1906</th>\n",
       "      <th>1907</th>\n",
       "      <th>1908</th>\n",
       "      <th>1909</th>\n",
       "      <th>1910</th>\n",
       "      <th>1911</th>\n",
       "      <th>1912</th>\n",
       "      <th>1913</th>\n",
       "      <th>1914</th>\n",
       "      <th>1915</th>\n",
       "      <th>1916</th>\n",
       "      <th>1917</th>\n",
       "      <th>1918</th>\n",
       "      <th>1919</th>\n",
       "      <th>1920</th>\n",
       "      <th>1921</th>\n",
       "      <th>1922</th>\n",
       "      <th>1923</th>\n",
       "      <th>1924</th>\n",
       "      <th>1925</th>\n",
       "      <th>1926</th>\n",
       "      <th>1927</th>\n",
       "      <th>1928</th>\n",
       "      <th>1929</th>\n",
       "      <th>1930</th>\n",
       "      <th>1931</th>\n",
       "      <th>1932</th>\n",
       "      <th>1933</th>\n",
       "      <th>1934</th>\n",
       "      <th>1935</th>\n",
       "      <th>1936</th>\n",
       "      <th>1937</th>\n",
       "      <th>1938</th>\n",
       "      <th>1939</th>\n",
       "      <th>1940</th>\n",
       "      <th>1941</th>\n",
       "      <th>1942</th>\n",
       "      <th>1943</th>\n",
       "      <th>1944</th>\n",
       "      <th>1945</th>\n",
       "      <th>1946</th>\n",
       "      <th>1947</th>\n",
       "      <th>1948</th>\n",
       "      <th>1949</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15    16    17    18    19    20    21    22    23    24    25    26    27    28    29    30    31    32    33    34    35    36    37    38    39    40    41    42    43    44    45    46    47    48    49    50    51    52    53    54    55    56    57    58    59    60    61    62    63    64    65    66    67    68    69    70    71    72    73    74    75    76    77    78    79    80    81    82    83    84    85    86    87    88    89    90    91    92    93    94    95    96    97    98    99    100   101   102   103   104   105   106   107   108   109   110   111   112   113   114   115   116   117   118   119   120   121   122   123   124   125   126   127   128   129   130   131   132   133   134   135   136   137   138   139   140   141   142   143   144   145   146   147   148   149   150   151   152   153   154   155   156   157   158   159   160   161   162   163   164   165   \\\n",
       "0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "1   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "\n",
       "   166   167   168   169   170   171   172   173   174   175   176   177   178   179   180   181   182   183   184   185   186   187   188   189   190   191   192   193   194   195   196   197   198   199   200   201   202   203   204   205   206   207   208   209   210   211   212   213   214   215   216   217   218   219   220   221   222   223   224   225   226   227   228   229   230   231   232   233   234   235   236   237   238   239   240   241   242   243   244   245   246   247   248   249   ...  1750  1751  1752  1753  1754  1755  1756  1757  1758  1759  1760  1761  1762  1763  1764  1765  1766  1767  1768  1769  1770  1771  1772  1773  1774  1775  1776  1777  1778  1779  1780  1781  1782  1783  1784  1785  1786  1787  1788  1789  1790  1791  1792  1793  1794  1795  1796  1797  1798  1799  1800  1801  1802  1803  1804  1805  1806  1807  1808  1809  1810  1811  1812  1813  1814  1815  1816  1817  1818  1819  1820  1821  1822  1823  1824  1825  1826  1827  1828  1829  1830  \\\n",
       "0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  ...  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0   1.0   \n",
       "1   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  ...  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0   1.0   \n",
       "\n",
       "   1831  1832  1833  1834  1835  1836  1837  1838  1839  1840  1841  1842  1843  1844  1845  1846  1847  1848  1849  1850  1851  1852  1853  1854  1855  1856  1857  1858  1859  1860  1861  1862  1863  1864  1865  1866  1867  1868  1869  1870  1871  1872  1873  1874  1875  1876  1877  1878  1879  1880  1881  1882  1883  1884  1885  1886  1887  1888  1889  1890  1891  1892  1893  1894  1895  1896  1897  1898  1899  1900  1901  1902  1903  1904  1905  1906  1907  1908  1909  1910  1911  1912  1913  1914  1915  1916  1917  1918  1919  1920  1921  1922  1923  1924  1925  1926  1927  1928  1929  1930  1931  1932  1933  1934  1935  1936  1937  1938  1939  1940  1941  1942  1943  1944  1945  1946  1947  1948  1949  1950  1951  1952  1953  1954  1955  1956  1957  1958  1959  1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  1971  1972  1973  1974  1975  1976  1977  1978  1979  1980  1981  1982  1983  1984  1985  1986  1987  1988  1989  1990  1991  1992  1993  1994  1995  1996  \\\n",
       "0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   \n",
       "1  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   \n",
       "\n",
       "   1997  1998  1999  \n",
       "0  -1.0   1.0  -1.0  \n",
       "1  -1.0   1.0  -1.0  \n",
       "\n",
       "[2 rows x 2000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmv_indx = [0, 2, 3, 4, 6, 8, 12, 20, 23]\n",
    "test_list, y_list, ids_list = split_data_for_test_submit(ids_sample, X_sample, y_sample, rmv_indx)\n",
    "#y_pred = predict_label()\n",
    "# Store prediction in a list, Here we need to replace y_list by prediction_list\n",
    "y_r = np.concatenate((y_list[0], y_list[1], y_list[2], y_list[3]), axis=0)[:, np.newaxis]\n",
    "ids_r = np.concatenate((ids_list[0], ids_list[1], ids_list[2], ids_list[3]), axis=0)[:, np.newaxis]\n",
    "sorted_arr = np.concatenate((ids_r, y_r), axis=1)\n",
    "sorted_arr = sorted_arr[sorted_arr[:, 0].argsort()]\n",
    "rec_y = np.squeeze(np.delete(sorted_arr, 0, axis=1))\n",
    "sum_ = sum(y_sample - rec_y)\n",
    "print(sum_)\n",
    "pd.DataFrame([y_sample, rec_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82e9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52c9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d618d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04e376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "marked-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "[ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "[22 23 29]\n",
      "[21 22 29]\n"
     ]
    }
   ],
   "source": [
    "new_data, _, rmv_ind = preprocess_train_data_split(tX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0ceda3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5  6 12 23 24 25 26 27 28] [ 4  5  6 12 22 23 24 25 26 27 28 29]\n",
      "[ 4  5  6 12 26 27 28] [ 4  5  6 12 22 26 27 28]\n",
      "[] 22\n",
      "[] 22\n"
     ]
    }
   ],
   "source": [
    "data_list, y_list, feat_ind = subdivide_data(tX, y)\n",
    "new_data_list = []\n",
    "for tx in data_list:\n",
    "    _, irr_ind = delete_irr_features(tx, 0.5)\n",
    "    _, norm_ind = normalize_data(tx)\n",
    "    print(irr_ind, norm_ind)\n",
    "    ind = norm_ind\n",
    "    ind = np.insert(ind, -1, irr_ind)\n",
    "    ind = np.unique(ind)\n",
    "    new_data = np.delete(tx, ind, axis=1)\n",
    "    new_data_list.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "comparable-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_mat_0 = np.ma.corrcoef(new_data_list[0], rowvar=False)\n",
    "corr_mat_1 = np.ma.corrcoef(new_data_list[1], rowvar=False)\n",
    "corr_mat_2 = np.ma.corrcoef(new_data_list[2], rowvar=False)\n",
    "corr_mat_3 = np.ma.corrcoef(new_data_list[3], rowvar=False)\n",
    "\n",
    "corr_mat_list = [corr_mat_0, corr_mat_1, corr_mat_2, corr_mat_3]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(1, 5):\n",
    "    fig.add_subplot(4, 4, i)\n",
    "    plt.imshow(np.abs(corr_mat_list[i - 1]), cmap='Blues')\n",
    "    plt.xlabel('index of feature')\n",
    "    #plt.ylabel('index of feature')\n",
    "    #plt.savefig('../figs/corr_matrices.png', bbox_inches='tight')  \n",
    "    \n",
    "for i, corr in enumerate(corr_mat_list):\n",
    "    corr_mat_list[i][corr <= 0.9] = 0\n",
    "    corr_mat_list[i][corr > 0.9] = 1\n",
    "\n",
    "for i in range(5, 9):\n",
    "    fig.add_subplot(4, 4, i)\n",
    "    plt.imshow(np.abs(corr_mat_list[i - 5]), cmap='Blues')\n",
    "    plt.xlabel('index of feature')\n",
    "    #plt.ylabel('index of feature')\n",
    "    plt.savefig('../figs/corr_matrices.png', bbox_inches='tight')  \n",
    "plt.show() \n",
    "#plt.imshow(np.abs(corr_mat), cmap='Blues')\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "placed-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2]\n",
      " [ 3  9]\n",
      " [ 3 23]\n",
      " [ 3 29]\n",
      " [ 4  5]\n",
      " [ 9 21]\n",
      " [ 9 23]\n",
      " [ 9 29]\n",
      " [21 29]\n",
      " [22 29]\n",
      " [23 29]\n",
      " [26 29]]\n"
     ]
    }
   ],
   "source": [
    "corr_indices = np.argwhere(np.abs(np.triu(corr_mat - np.eye(30))) > 0.8)\n",
    "print(corr_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "simplified-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  4  9 21 22 23 26] [ 2  5  9 21 23 29]\n"
     ]
    }
   ],
   "source": [
    "unique_ind1 = np.unique(corr_indices[:, 0])\n",
    "unique_ind2 = np.unique(corr_indices[:, 1])\n",
    "print(unique_ind1, unique_ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "informative-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "len1 = len(unique_ind1)\n",
    "len2 = len(unique_ind2)\n",
    "corr_ind_reduce_short = (unique_ind1, unique_ind2)[len(unique_ind1) > len(unique_ind2)]\n",
    "corr_ind_reduce_big = (unique_ind1, unique_ind2)[len(unique_ind1) < len(unique_ind2)]\n",
    "corr_ind_to_keep = []\n",
    "for ind in corr_ind_reduce_short:\n",
    "    is_in = np.isin(ind, corr_ind_reduce_big)\n",
    "    if not is_in:\n",
    "        corr_ind_to_keep.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dried-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "all_ind = np.unique(corr_indices.flatten())\n",
    "print(all_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "verbal-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ind_to_throw = np.setdiff1d(all_ind, corr_ind_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "illegal-strip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  5, 29]), array([ 0,  3,  4,  9, 21, 22, 23, 26]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(corr_ind_to_keep), corr_ind_to_throw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-arrival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-basic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-dubai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "connected-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep, throw = feature_selection(new_data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ordered-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  5, 29]), array([ 0,  3,  4,  9, 21, 22, 23, 26]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep, throw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-poker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2f402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8864d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b5cc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4,  5,  6,  8, 12, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      " array([ 3,  4,  5,  6,  9, 12, 22, 23, 26, 27, 28])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AntoineDaeniker/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ind = np.array((rmv_ind[0], rmv_ind[1]))\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1520b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some errors were detected !\n    Line #3 (got 29 columns instead of 21)\n    Line #4 (got 28 columns instead of 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f3/3d8xjmhn3lb1y_bqwhqfy7t80000gn/T/ipykernel_21387/498828476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../sgd_model_split.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/EPFL/Master 1/ML_course/ML_project/utils/io_utils.py\u001b[0m in \u001b[0;36mload_csv_data\u001b[0;34m(data_path, sub_sample)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;31m# Raise an exception ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minvalid_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m             \u001b[0;31m# Issue a warning ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Some errors were detected !\n    Line #3 (got 29 columns instead of 21)\n    Line #4 (got 28 columns instead of 21)"
     ]
    }
   ],
   "source": [
    "ws = load_csv_data('../sgd_model_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e1564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
