{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "czech-intro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../')\n",
    "from utils.implementation_utils import *\n",
    "from utils.preprocessing_utils import *\n",
    "import datetime\n",
    "from model import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sized-novel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,) (250000, 30)\n"
     ]
    }
   ],
   "source": [
    "from utils.io_utils import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, tXt, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(y.shape, tX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "08f082b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_data_split_(X, y, degree, update_label=True):\n",
    "    logger.info('Preprocessing data')\n",
    "    X_list, y_list, feat_ind = subdivide_data(X, y)\n",
    "    data_split = []\n",
    "    y_split = []\n",
    "    rmv_idx_split = []\n",
    "\n",
    "    for X, y in zip(X_list, y_list):\n",
    "        _, irr_ind = delete_irr_features(X, 0.5)\n",
    "        _, corr_ind,_ = feature_correlation(X, 0.9)\n",
    "        _, norm_ind = normalize_data(X)\n",
    "\n",
    "        rmv_idx = np.unique(np.concatenate((irr_ind, corr_ind)))\n",
    "        rmv_idx = np.insert(rmv_idx, -1, norm_ind)\n",
    "        rmv_idx = np.insert(rmv_idx, -1, feat_ind)\n",
    "        rmv_idx = np.unique(rmv_idx)\n",
    "        print('Removed features indexes : ', rmv_idx)\n",
    "        data_reduce = np.delete(X, rmv_idx, axis=1)\n",
    "        data_poly = build_poly(data_reduce, degree_start=0, degree_end=degree, include_half=False, include_cross_terms=False)\n",
    "        data_irr_corr_norm,_ = normalize_data(data_poly)\n",
    "\n",
    "        if update_label:\n",
    "            y = update_labels(y)\n",
    "\n",
    "        data_split.append(data_irr_corr_norm)\n",
    "        y_split.append(y)\n",
    "        rmv_idx_split.append(rmv_idx)\n",
    "\n",
    "    return data_split, y_split, rmv_idx_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cca30ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(X, y, rmv_idx, lambda_=1e-8, max_iters=800, gamma=1e-7, batch_size=1, save_weights=False, add_bias_term=True):\n",
    "    # w, loss = ridge_regression(y, X, lambda_=1e-8)\n",
    "    w, loss = reg_logistic_regression(\n",
    "        y=y,\n",
    "        tx=X,\n",
    "        lambda_=lambda_,\n",
    "        initial_w=np.zeros(X.shape[1]),\n",
    "        max_iters=max_iters,\n",
    "        gamma=gamma,\n",
    "    )\n",
    "\n",
    "    logger.info(f'Final loss value for trained model: {loss}')\n",
    "\n",
    "    # for i in rmv_idx:\n",
    "    #     w = np.insert(w, i, 0)\n",
    "\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1826cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_split_(save_weights=False, retrain=True, internal_test=True, create_submission=False, add_bias_term=True):\n",
    "    y_btrain, X_btrain, Xt, ids = load_csv_data('../data/train.csv')\n",
    "    print('Data shape: ', y_btrain.shape, X_btrain.shape)\n",
    "    degrees = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    #lambdas = [1e-1, 1e-5, 1e-8]\n",
    "    #accuracys_per_lambda = []\n",
    "    #for lambda_ in lambdas:\n",
    "    accuracys_per_degree = []\n",
    "    for degree in degrees:\n",
    "        X_list, y_list, rmv_idx_list = preprocess_train_data_split_(X_btrain, y_btrain, degree)\n",
    "        ws = []\n",
    "        accuracys_split = []\n",
    "        for i, (y, X, rmv_idx), in enumerate(zip(y_list, X_list, rmv_idx_list)):\n",
    "            print(X.shape)\n",
    "            if add_bias_term:\n",
    "                X = np.concatenate((np.ones(X.shape[0])[:, np.newaxis], X), axis=1)\n",
    "            k_fold = 10\n",
    "            k_indices = build_k_indices(y, k_fold)\n",
    "            w_split = []\n",
    "            accuracys_k = []\n",
    "            for k in range(1):\n",
    "                start_time = datetime.now()\n",
    "                X_train, y_train, X_test, y_test = split_cross_validation(y, X, k_indices, k)\n",
    "                y_train_dist = np.asarray((np.unique(y_train, return_counts=True))).T\n",
    "                y_test_dist = np.asarray((np.unique(y_test, return_counts=True))).T\n",
    "                #with np.printoptions(precision=0, suppress=True):\n",
    "                #    print(f'y_train distribution: {y_train_dist} \\ny_test distribution: {y_test_dist}')\n",
    "\n",
    "                if not retrain:\n",
    "                    w = np.loadtxt('sgd_model.csv', delimiter=',')\n",
    "                else:\n",
    "                    w, loss = train_(X_train, y_train, rmv_idx)\n",
    "                    w_split.append(w)\n",
    "                    end_time = datetime.now()\n",
    "                    exection_time = (end_time - start_time).total_seconds()\n",
    "                    print(\"Model training time={t:.3f} seconds\".format(t=exection_time))\n",
    "\n",
    "                if internal_test:\n",
    "                    print(f'Test for datasplit : {i}, k {k} and degree {degree}')\n",
    "                    accuracys_k.append(test_(w, X_test, y_test))\n",
    "            ws.append(w_split)\n",
    "            print(\"MAX accuracys_k\", np.max(accuracys_k))\n",
    "            accuracys_split.append(np.max(accuracys_k))\n",
    "        print(\"MAX accuracys_split\", np.max(accuracys_split))\n",
    "        accuracys_per_degree.append(np.max(accuracys_split))\n",
    "            \n",
    "            #ws_best = find_best_w(ws, losses)\n",
    "            #print('Best weights : ',ws_best)\n",
    "        #accuracys_per_lambda.append(accuracys_per_degree)\n",
    "\n",
    "        \n",
    "    return accuracys_per_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c3ffcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(w, X_test, y_test):\n",
    "    y_pred = predict_labels(w, X_test)\n",
    "    y_test[np.where(y_test <= 0)] = -1\n",
    "    accuracy = get_accuracy(y_pred, y_test)\n",
    "    print(f'Model accuracy: {accuracy}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a1c1f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (250000,) (250000, 30)\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 34 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 38 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 54 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 54 terms and 27 zero terms.\n",
      "(99913, 34)\n",
      "1e-08\n",
      "Model training time=8.004 seconds\n",
      "Test for datasplit : 0, k 0 and degree 1\n",
      "y_pred mean :  -0.9191305373893401\n",
      "Model accuracy: 81.65348813932539\n",
      "MAX accuracys_k 81.65348813932539\n",
      "(77544, 38)\n",
      "1e-08\n",
      "Model training time=6.440 seconds\n",
      "Test for datasplit : 1, k 0 and degree 1\n",
      "y_pred mean :  -0.45196055624004033\n",
      "Model accuracy: 69.93809646633996\n",
      "MAX accuracys_k 69.93809646633996\n",
      "(50379, 54)\n",
      "1e-08\n",
      "Model training time=5.140 seconds\n",
      "Test for datasplit : 2, k 0 and degree 1\n",
      "y_pred mean :  0.04262121908361609\n",
      "Model accuracy: 71.29243597379393\n",
      "MAX accuracys_k 71.29243597379393\n",
      "(22164, 54)\n",
      "1e-08\n",
      "Model training time=2.316 seconds\n",
      "Test for datasplit : 3, k 0 and degree 1\n",
      "y_pred mean :  -0.2606486760533171\n",
      "Model accuracy: 69.58483754512635\n",
      "MAX accuracys_k 69.58483754512635\n",
      "MAX accuracys_split 81.65348813932539\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 51 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 57 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 81 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 81 terms and 27 zero terms.\n",
      "(99913, 51)\n",
      "1e-08\n",
      "Model training time=10.082 seconds\n",
      "Test for datasplit : 0, k 0 and degree 2\n",
      "y_pred mean :  -0.9354308901436611\n",
      "Model accuracy: 82.57431688519668\n",
      "MAX accuracys_k 82.57431688519668\n",
      "(77544, 57)\n",
      "1e-08\n",
      "Model training time=11.962 seconds\n",
      "Test for datasplit : 1, k 0 and degree 2\n",
      "y_pred mean :  -0.4523813181757452\n",
      "Model accuracy: 72.71085891152953\n",
      "MAX accuracys_k 72.71085891152953\n",
      "(50379, 81)\n",
      "1e-08\n",
      "Model training time=8.135 seconds\n",
      "Test for datasplit : 2, k 0 and degree 2\n",
      "y_pred mean :  0.06249810941283816\n",
      "Model accuracy: 72.44391502878698\n",
      "MAX accuracys_k 72.44391502878698\n",
      "(22164, 81)\n",
      "1e-08\n",
      "Model training time=7.353 seconds\n",
      "Test for datasplit : 3, k 0 and degree 2\n",
      "y_pred mean :  -0.2577285525838433\n",
      "Model accuracy: 69.0884476534296\n",
      "MAX accuracys_k 69.0884476534296\n",
      "MAX accuracys_split 82.57431688519668\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 68 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 76 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 108 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 108 terms and 27 zero terms.\n",
      "(99913, 68)\n",
      "1e-08\n",
      "Model training time=13.545 seconds\n",
      "Test for datasplit : 0, k 0 and degree 3\n",
      "y_pred mean :  -0.9350492641199063\n",
      "Model accuracy: 82.54428986087478\n",
      "MAX accuracys_k 82.54428986087478\n",
      "(77544, 76)\n",
      "1e-08\n",
      "Model training time=9.566 seconds\n",
      "Test for datasplit : 1, k 0 and degree 3\n",
      "y_pred mean :  -0.4557773588917632\n",
      "Model accuracy: 72.73665205055455\n",
      "MAX accuracys_k 72.73665205055455\n",
      "(50379, 108)\n",
      "1e-08\n",
      "Model training time=7.636 seconds\n",
      "Test for datasplit : 2, k 0 and degree 3\n",
      "y_pred mean :  0.06760824085314035\n",
      "Model accuracy: 72.36450268016677\n",
      "MAX accuracys_k 72.36450268016677\n",
      "(22164, 108)\n",
      "1e-08\n",
      "Model training time=3.544 seconds\n",
      "Test for datasplit : 3, k 0 and degree 3\n",
      "y_pred mean :  -0.25560775163636923\n",
      "Model accuracy: 69.44945848375451\n",
      "MAX accuracys_k 69.44945848375451\n",
      "MAX accuracys_split 82.54428986087478\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 85 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 95 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 135 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 135 terms and 27 zero terms.\n",
      "(99913, 85)\n",
      "1e-08\n",
      "Model training time=12.920 seconds\n",
      "Test for datasplit : 0, k 0 and degree 4\n",
      "y_pred mean :  -0.9380650151368721\n",
      "Model accuracy: 82.58432589330397\n",
      "MAX accuracys_k 82.58432589330397\n",
      "(77544, 95)\n",
      "1e-08\n",
      "Model training time=10.790 seconds\n",
      "Test for datasplit : 1, k 0 and degree 4\n",
      "y_pred mean :  -0.4591966573967786\n",
      "Model accuracy: 72.31106525664174\n",
      "MAX accuracys_k 72.31106525664174\n",
      "(50379, 135)\n",
      "1e-08\n",
      "Model training time=12.957 seconds\n",
      "Test for datasplit : 2, k 0 and degree 4\n",
      "y_pred mean :  0.07314339282467301\n",
      "Model accuracy: 72.40420885447688\n",
      "MAX accuracys_k 72.40420885447688\n",
      "(22164, 135)\n",
      "1e-08\n",
      "Model training time=4.169 seconds\n",
      "Test for datasplit : 3, k 0 and degree 4\n",
      "y_pred mean :  -0.2536192842987895\n",
      "Model accuracy: 69.81046931407943\n",
      "MAX accuracys_k 69.81046931407943\n",
      "MAX accuracys_split 82.58432589330397\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 102 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 114 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 162 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 162 terms and 27 zero terms.\n",
      "(99913, 102)\n",
      "1e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../utils/implementation_utils.py:261: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_i = y.T.dot(np.log(pred)) + (1 - y).T.dot(np.log(1 - pred))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training time=18.316 seconds\n",
      "Test for datasplit : 0, k 0 and degree 5\n",
      "y_pred mean :  -0.9386728328130675\n",
      "Model accuracy: 82.60434390951856\n",
      "MAX accuracys_k 82.60434390951856\n",
      "(77544, 114)\n",
      "1e-08\n",
      "Model training time=13.106 seconds\n",
      "Test for datasplit : 1, k 0 and degree 5\n",
      "y_pred mean :  -0.4608658402654785\n",
      "Model accuracy: 72.31106525664174\n",
      "MAX accuracys_k 72.31106525664174\n",
      "(50379, 162)\n",
      "1e-08\n",
      "Model training time=10.838 seconds\n",
      "Test for datasplit : 2, k 0 and degree 5\n",
      "y_pred mean :  0.07429197404464971\n",
      "Model accuracy: 72.34464959301171\n",
      "MAX accuracys_k 72.34464959301171\n",
      "(22164, 162)\n",
      "1e-08\n",
      "Model training time=4.869 seconds\n",
      "Test for datasplit : 3, k 0 and degree 5\n",
      "y_pred mean :  -0.25247587126825766\n",
      "Model accuracy: 69.62996389891697\n",
      "MAX accuracys_k 69.62996389891697\n",
      "MAX accuracys_split 82.60434390951856\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 119 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 133 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 189 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 189 terms and 27 zero terms.\n",
      "(99913, 119)\n",
      "1e-08\n",
      "Model training time=16.566 seconds\n",
      "Test for datasplit : 0, k 0 and degree 6\n",
      "y_pred mean :  -0.9399409721167302\n",
      "Model accuracy: 82.55429886898209\n",
      "MAX accuracys_k 82.55429886898209\n",
      "(77544, 133)\n",
      "1e-08\n",
      "Model training time=13.769 seconds\n",
      "Test for datasplit : 1, k 0 and degree 6\n",
      "y_pred mean :  -0.4624152226519541\n",
      "Model accuracy: 72.28527211761671\n",
      "MAX accuracys_k 72.28527211761671\n",
      "(50379, 189)\n",
      "1e-08\n",
      "Model training time=11.410 seconds\n",
      "Test for datasplit : 2, k 0 and degree 6\n",
      "y_pred mean :  0.07565014263993328\n",
      "Model accuracy: 72.32479650585667\n",
      "MAX accuracys_k 72.32479650585667\n",
      "(22164, 189)\n",
      "1e-08\n",
      "Model training time=5.378 seconds\n",
      "Test for datasplit : 3, k 0 and degree 6\n",
      "y_pred mean :  -0.25153995973473925\n",
      "Model accuracy: 69.58483754512635\n",
      "MAX accuracys_k 69.58483754512635\n",
      "MAX accuracys_split 82.55429886898209\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 136 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 152 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 216 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 216 terms and 27 zero terms.\n",
      "(99913, 136)\n",
      "1e-08\n",
      "Model training time=20.571 seconds\n",
      "Test for datasplit : 0, k 0 and degree 7\n",
      "y_pred mean :  -0.9405530737850503\n",
      "Model accuracy: 82.60434390951856\n",
      "MAX accuracys_k 82.60434390951856\n",
      "(77544, 152)\n",
      "1e-08\n",
      "Model training time=14.613 seconds\n",
      "Test for datasplit : 1, k 0 and degree 7\n",
      "y_pred mean :  -0.46311135443804163\n",
      "Model accuracy: 72.34975496517926\n",
      "MAX accuracys_k 72.34975496517926\n",
      "(50379, 216)\n",
      "1e-08\n",
      "Model training time=13.014 seconds\n",
      "Test for datasplit : 2, k 0 and degree 7\n",
      "y_pred mean :  0.07567296219828988\n",
      "Model accuracy: 72.18582489577129\n",
      "MAX accuracys_k 72.18582489577129\n",
      "(22164, 216)\n",
      "1e-08\n",
      "Model training time=6.007 seconds\n",
      "Test for datasplit : 3, k 0 and degree 7\n",
      "y_pred mean :  -0.25097995037191184\n",
      "Model accuracy: 69.67509025270758\n",
      "MAX accuracys_k 69.67509025270758\n",
      "MAX accuracys_split 82.60434390951856\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 153 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 171 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 243 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 243 terms and 27 zero terms.\n",
      "(99913, 153)\n",
      "1e-08\n",
      "Model training time=30.893 seconds\n",
      "Test for datasplit : 0, k 0 and degree 8\n",
      "y_pred mean :  -0.9413057542052721\n",
      "Model accuracy: 82.62436192573315\n",
      "MAX accuracys_k 82.62436192573315\n",
      "(77544, 171)\n",
      "1e-08\n",
      "Model training time=18.927 seconds\n",
      "Test for datasplit : 1, k 0 and degree 8\n",
      "y_pred mean :  -0.4639866426189273\n",
      "Model accuracy: 72.38844467371679\n",
      "MAX accuracys_k 72.38844467371679\n",
      "(50379, 243)\n",
      "1e-08\n",
      "Model training time=34.728 seconds\n",
      "Test for datasplit : 2, k 0 and degree 8\n",
      "y_pred mean :  0.07564991796492286\n",
      "Model accuracy: 72.20567798292635\n",
      "MAX accuracys_k 72.20567798292635\n",
      "(22164, 243)\n",
      "1e-08\n",
      "Model training time=10.353 seconds\n",
      "Test for datasplit : 3, k 0 and degree 8\n",
      "y_pred mean :  -0.25048837004143854\n",
      "Model accuracy: 69.7653429602888\n",
      "MAX accuracys_k 69.7653429602888\n",
      "MAX accuracys_split 82.62436192573315\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 170 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 190 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 270 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 270 terms and 27 zero terms.\n",
      "(99913, 170)\n",
      "1e-08\n",
      "Model training time=31.155 seconds\n",
      "Test for datasplit : 0, k 0 and degree 9\n",
      "y_pred mean :  -0.941905173049325\n",
      "Model accuracy: 82.62436192573315\n",
      "MAX accuracys_k 82.62436192573315\n",
      "(77544, 190)\n",
      "1e-08\n",
      "Model training time=29.424 seconds\n",
      "Test for datasplit : 1, k 0 and degree 9\n",
      "y_pred mean :  -0.46428347251744323\n",
      "Model accuracy: 72.36265153469178\n",
      "MAX accuracys_k 72.36265153469178\n",
      "(50379, 270)\n",
      "1e-08\n",
      "Model training time=26.298 seconds\n",
      "Test for datasplit : 2, k 0 and degree 9\n",
      "y_pred mean :  0.07541902535040913\n",
      "Model accuracy: 72.20567798292635\n",
      "MAX accuracys_k 72.20567798292635\n",
      "(22164, 270)\n",
      "1e-08\n",
      "Model training time=16.959 seconds\n",
      "Test for datasplit : 3, k 0 and degree 9\n",
      "y_pred mean :  -0.25018771790945493\n",
      "Model accuracy: 69.62996389891697\n",
      "MAX accuracys_k 69.62996389891697\n",
      "MAX accuracys_split 82.62436192573315\n",
      "Removed features indexes :  [ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "Generating polynomial with 187 terms and 17 zero terms.\n",
      "Removed features indexes :  [ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "Generating polynomial with 209 terms and 19 zero terms.\n",
      "Removed features indexes :  [22 23 29]\n",
      "Generating polynomial with 297 terms and 27 zero terms.\n",
      "Removed features indexes :  [21 22 29]\n",
      "Generating polynomial with 297 terms and 27 zero terms.\n",
      "(99913, 187)\n",
      "1e-08\n",
      "Model training time=26.774 seconds\n",
      "Test for datasplit : 0, k 0 and degree 10\n",
      "y_pred mean :  -0.9423424706223629\n",
      "Model accuracy: 82.60434390951856\n",
      "MAX accuracys_k 82.60434390951856\n",
      "(77544, 209)\n",
      "1e-08\n",
      "Model training time=30.063 seconds\n",
      "Test for datasplit : 1, k 0 and degree 10\n",
      "y_pred mean :  -0.46469512038575217\n",
      "Model accuracy: 72.42713438225432\n",
      "MAX accuracys_k 72.42713438225432\n",
      "(50379, 297)\n",
      "1e-08\n",
      "Model training time=26.860 seconds\n",
      "Test for datasplit : 2, k 0 and degree 10\n",
      "y_pred mean :  0.07489765078051237\n",
      "Model accuracy: 72.2255310700814\n",
      "MAX accuracys_k 72.2255310700814\n",
      "(22164, 297)\n",
      "1e-08\n",
      "Model training time=8.986 seconds\n",
      "Test for datasplit : 3, k 0 and degree 10\n",
      "y_pred mean :  -0.2498235042455474\n",
      "Model accuracy: 69.49458483754513\n",
      "MAX accuracys_k 69.49458483754513\n",
      "MAX accuracys_split 82.60434390951856\n"
     ]
    }
   ],
   "source": [
    "accuracy = run_model_split_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0b89910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81.65348813932539, 82.57431688519668, 82.54428986087478, 82.58432589330397, 82.60434390951856, 82.55429886898209, 82.60434390951856, 82.62436192573315, 82.62436192573315, 82.60434390951856]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffa4bf49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot lines\n",
    "x = np.arange(1, 11)\n",
    "plt.plot(x, accuracy, 'o-')\n",
    "plt.xlabel('degree polynomial')\n",
    "plt.ylabel('% accuracy')\n",
    "#plt.plot(x, accuracy[1], label = \"line 2\")\n",
    "#plt.plot(x, accuracy[2], label = \"line 3\")\n",
    "#plt.legend()\n",
    "plt.savefig('../figs/pol_degree_acc.png', bbox_inches='tight') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d38129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe471275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0     1.0\n",
       "1    -1.0\n",
       "2    -1.0\n",
       "3    -1.0\n",
       "4    -1.0\n",
       "...   ...\n",
       "1995  1.0\n",
       "1996 -1.0\n",
       "1997 -1.0\n",
       "1998  1.0\n",
       "1999 -1.0\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_range = [0, 2000]\n",
    "X_sample = tX[sample_range[0] : sample_range[1]]\n",
    "y_sample = y[sample_range[0] : sample_range[1]]\n",
    "ids_sample = ids[sample_range[0] : sample_range[1]]\n",
    "pd.DataFrame(y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c904a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "      <th>105</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>109</th>\n",
       "      <th>110</th>\n",
       "      <th>111</th>\n",
       "      <th>112</th>\n",
       "      <th>113</th>\n",
       "      <th>114</th>\n",
       "      <th>115</th>\n",
       "      <th>116</th>\n",
       "      <th>117</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "      <th>168</th>\n",
       "      <th>169</th>\n",
       "      <th>170</th>\n",
       "      <th>171</th>\n",
       "      <th>172</th>\n",
       "      <th>173</th>\n",
       "      <th>174</th>\n",
       "      <th>175</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>...</th>\n",
       "      <th>1750</th>\n",
       "      <th>1751</th>\n",
       "      <th>1752</th>\n",
       "      <th>1753</th>\n",
       "      <th>1754</th>\n",
       "      <th>1755</th>\n",
       "      <th>1756</th>\n",
       "      <th>1757</th>\n",
       "      <th>1758</th>\n",
       "      <th>1759</th>\n",
       "      <th>1760</th>\n",
       "      <th>1761</th>\n",
       "      <th>1762</th>\n",
       "      <th>1763</th>\n",
       "      <th>1764</th>\n",
       "      <th>1765</th>\n",
       "      <th>1766</th>\n",
       "      <th>1767</th>\n",
       "      <th>1768</th>\n",
       "      <th>1769</th>\n",
       "      <th>1770</th>\n",
       "      <th>1771</th>\n",
       "      <th>1772</th>\n",
       "      <th>1773</th>\n",
       "      <th>1774</th>\n",
       "      <th>1775</th>\n",
       "      <th>1776</th>\n",
       "      <th>1777</th>\n",
       "      <th>1778</th>\n",
       "      <th>1779</th>\n",
       "      <th>1780</th>\n",
       "      <th>1781</th>\n",
       "      <th>1782</th>\n",
       "      <th>1783</th>\n",
       "      <th>1784</th>\n",
       "      <th>1785</th>\n",
       "      <th>1786</th>\n",
       "      <th>1787</th>\n",
       "      <th>1788</th>\n",
       "      <th>1789</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>1792</th>\n",
       "      <th>1793</th>\n",
       "      <th>1794</th>\n",
       "      <th>1795</th>\n",
       "      <th>1796</th>\n",
       "      <th>1797</th>\n",
       "      <th>1798</th>\n",
       "      <th>1799</th>\n",
       "      <th>1800</th>\n",
       "      <th>1801</th>\n",
       "      <th>1802</th>\n",
       "      <th>1803</th>\n",
       "      <th>1804</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>1809</th>\n",
       "      <th>1810</th>\n",
       "      <th>1811</th>\n",
       "      <th>1812</th>\n",
       "      <th>1813</th>\n",
       "      <th>1814</th>\n",
       "      <th>1815</th>\n",
       "      <th>1816</th>\n",
       "      <th>1817</th>\n",
       "      <th>1818</th>\n",
       "      <th>1819</th>\n",
       "      <th>1820</th>\n",
       "      <th>1821</th>\n",
       "      <th>1822</th>\n",
       "      <th>1823</th>\n",
       "      <th>1824</th>\n",
       "      <th>1825</th>\n",
       "      <th>1826</th>\n",
       "      <th>1827</th>\n",
       "      <th>1828</th>\n",
       "      <th>1829</th>\n",
       "      <th>1830</th>\n",
       "      <th>1831</th>\n",
       "      <th>1832</th>\n",
       "      <th>1833</th>\n",
       "      <th>1834</th>\n",
       "      <th>1835</th>\n",
       "      <th>1836</th>\n",
       "      <th>1837</th>\n",
       "      <th>1838</th>\n",
       "      <th>1839</th>\n",
       "      <th>1840</th>\n",
       "      <th>1841</th>\n",
       "      <th>1842</th>\n",
       "      <th>1843</th>\n",
       "      <th>1844</th>\n",
       "      <th>1845</th>\n",
       "      <th>1846</th>\n",
       "      <th>1847</th>\n",
       "      <th>1848</th>\n",
       "      <th>1849</th>\n",
       "      <th>1850</th>\n",
       "      <th>1851</th>\n",
       "      <th>1852</th>\n",
       "      <th>1853</th>\n",
       "      <th>1854</th>\n",
       "      <th>1855</th>\n",
       "      <th>1856</th>\n",
       "      <th>1857</th>\n",
       "      <th>1858</th>\n",
       "      <th>1859</th>\n",
       "      <th>1860</th>\n",
       "      <th>1861</th>\n",
       "      <th>1862</th>\n",
       "      <th>1863</th>\n",
       "      <th>1864</th>\n",
       "      <th>1865</th>\n",
       "      <th>1866</th>\n",
       "      <th>1867</th>\n",
       "      <th>1868</th>\n",
       "      <th>1869</th>\n",
       "      <th>1870</th>\n",
       "      <th>1871</th>\n",
       "      <th>1872</th>\n",
       "      <th>1873</th>\n",
       "      <th>1874</th>\n",
       "      <th>1875</th>\n",
       "      <th>1876</th>\n",
       "      <th>1877</th>\n",
       "      <th>1878</th>\n",
       "      <th>1879</th>\n",
       "      <th>1880</th>\n",
       "      <th>1881</th>\n",
       "      <th>1882</th>\n",
       "      <th>1883</th>\n",
       "      <th>1884</th>\n",
       "      <th>1885</th>\n",
       "      <th>1886</th>\n",
       "      <th>1887</th>\n",
       "      <th>1888</th>\n",
       "      <th>1889</th>\n",
       "      <th>1890</th>\n",
       "      <th>1891</th>\n",
       "      <th>1892</th>\n",
       "      <th>1893</th>\n",
       "      <th>1894</th>\n",
       "      <th>1895</th>\n",
       "      <th>1896</th>\n",
       "      <th>1897</th>\n",
       "      <th>1898</th>\n",
       "      <th>1899</th>\n",
       "      <th>1900</th>\n",
       "      <th>1901</th>\n",
       "      <th>1902</th>\n",
       "      <th>1903</th>\n",
       "      <th>1904</th>\n",
       "      <th>1905</th>\n",
       "      <th>1906</th>\n",
       "      <th>1907</th>\n",
       "      <th>1908</th>\n",
       "      <th>1909</th>\n",
       "      <th>1910</th>\n",
       "      <th>1911</th>\n",
       "      <th>1912</th>\n",
       "      <th>1913</th>\n",
       "      <th>1914</th>\n",
       "      <th>1915</th>\n",
       "      <th>1916</th>\n",
       "      <th>1917</th>\n",
       "      <th>1918</th>\n",
       "      <th>1919</th>\n",
       "      <th>1920</th>\n",
       "      <th>1921</th>\n",
       "      <th>1922</th>\n",
       "      <th>1923</th>\n",
       "      <th>1924</th>\n",
       "      <th>1925</th>\n",
       "      <th>1926</th>\n",
       "      <th>1927</th>\n",
       "      <th>1928</th>\n",
       "      <th>1929</th>\n",
       "      <th>1930</th>\n",
       "      <th>1931</th>\n",
       "      <th>1932</th>\n",
       "      <th>1933</th>\n",
       "      <th>1934</th>\n",
       "      <th>1935</th>\n",
       "      <th>1936</th>\n",
       "      <th>1937</th>\n",
       "      <th>1938</th>\n",
       "      <th>1939</th>\n",
       "      <th>1940</th>\n",
       "      <th>1941</th>\n",
       "      <th>1942</th>\n",
       "      <th>1943</th>\n",
       "      <th>1944</th>\n",
       "      <th>1945</th>\n",
       "      <th>1946</th>\n",
       "      <th>1947</th>\n",
       "      <th>1948</th>\n",
       "      <th>1949</th>\n",
       "      <th>1950</th>\n",
       "      <th>1951</th>\n",
       "      <th>1952</th>\n",
       "      <th>1953</th>\n",
       "      <th>1954</th>\n",
       "      <th>1955</th>\n",
       "      <th>1956</th>\n",
       "      <th>1957</th>\n",
       "      <th>1958</th>\n",
       "      <th>1959</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1     2     3     4     5     6     7     8     9     10    11    12    13    14    15    16    17    18    19    20    21    22    23    24    25    26    27    28    29    30    31    32    33    34    35    36    37    38    39    40    41    42    43    44    45    46    47    48    49    50    51    52    53    54    55    56    57    58    59    60    61    62    63    64    65    66    67    68    69    70    71    72    73    74    75    76    77    78    79    80    81    82    83    84    85    86    87    88    89    90    91    92    93    94    95    96    97    98    99    100   101   102   103   104   105   106   107   108   109   110   111   112   113   114   115   116   117   118   119   120   121   122   123   124   125   126   127   128   129   130   131   132   133   134   135   136   137   138   139   140   141   142   143   144   145   146   147   148   149   150   151   152   153   154   155   156   157   158   159   160   161   162   163   164   165   \\\n",
       "0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "1   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   \n",
       "\n",
       "   166   167   168   169   170   171   172   173   174   175   176   177   178   179   180   181   182   183   184   185   186   187   188   189   190   191   192   193   194   195   196   197   198   199   200   201   202   203   204   205   206   207   208   209   210   211   212   213   214   215   216   217   218   219   220   221   222   223   224   225   226   227   228   229   230   231   232   233   234   235   236   237   238   239   240   241   242   243   244   245   246   247   248   249   ...  1750  1751  1752  1753  1754  1755  1756  1757  1758  1759  1760  1761  1762  1763  1764  1765  1766  1767  1768  1769  1770  1771  1772  1773  1774  1775  1776  1777  1778  1779  1780  1781  1782  1783  1784  1785  1786  1787  1788  1789  1790  1791  1792  1793  1794  1795  1796  1797  1798  1799  1800  1801  1802  1803  1804  1805  1806  1807  1808  1809  1810  1811  1812  1813  1814  1815  1816  1817  1818  1819  1820  1821  1822  1823  1824  1825  1826  1827  1828  1829  1830  \\\n",
       "0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  ...  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0   1.0   \n",
       "1   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  ...  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0   1.0   \n",
       "\n",
       "   1831  1832  1833  1834  1835  1836  1837  1838  1839  1840  1841  1842  1843  1844  1845  1846  1847  1848  1849  1850  1851  1852  1853  1854  1855  1856  1857  1858  1859  1860  1861  1862  1863  1864  1865  1866  1867  1868  1869  1870  1871  1872  1873  1874  1875  1876  1877  1878  1879  1880  1881  1882  1883  1884  1885  1886  1887  1888  1889  1890  1891  1892  1893  1894  1895  1896  1897  1898  1899  1900  1901  1902  1903  1904  1905  1906  1907  1908  1909  1910  1911  1912  1913  1914  1915  1916  1917  1918  1919  1920  1921  1922  1923  1924  1925  1926  1927  1928  1929  1930  1931  1932  1933  1934  1935  1936  1937  1938  1939  1940  1941  1942  1943  1944  1945  1946  1947  1948  1949  1950  1951  1952  1953  1954  1955  1956  1957  1958  1959  1960  1961  1962  1963  1964  1965  1966  1967  1968  1969  1970  1971  1972  1973  1974  1975  1976  1977  1978  1979  1980  1981  1982  1983  1984  1985  1986  1987  1988  1989  1990  1991  1992  1993  1994  1995  1996  \\\n",
       "0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   \n",
       "1  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0   1.0   1.0  -1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0   1.0   1.0   1.0   1.0   1.0  -1.0  -1.0   1.0   1.0  -1.0  -1.0   1.0   1.0   1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0  -1.0  -1.0  -1.0  -1.0  -1.0   1.0  -1.0   \n",
       "\n",
       "   1997  1998  1999  \n",
       "0  -1.0   1.0  -1.0  \n",
       "1  -1.0   1.0  -1.0  \n",
       "\n",
       "[2 rows x 2000 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmv_indx = [0, 2, 3, 4, 6, 8, 12, 20, 23]\n",
    "test_list, y_list, ids_list = split_data_for_test_submit(ids_sample, X_sample, y_sample, rmv_indx)\n",
    "#y_pred = predict_label()\n",
    "# Store prediction in a list, Here we need to replace y_list by prediction_list\n",
    "y_r = np.concatenate((y_list[0], y_list[1], y_list[2], y_list[3]), axis=0)[:, np.newaxis]\n",
    "ids_r = np.concatenate((ids_list[0], ids_list[1], ids_list[2], ids_list[3]), axis=0)[:, np.newaxis]\n",
    "sorted_arr = np.concatenate((ids_r, y_r), axis=1)\n",
    "sorted_arr = sorted_arr[sorted_arr[:, 0].argsort()]\n",
    "rec_y = np.squeeze(np.delete(sorted_arr, 0, axis=1))\n",
    "sum_ = sum(y_sample - rec_y)\n",
    "print(sum_)\n",
    "pd.DataFrame([y_sample, rec_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82e9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52c9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02d618d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04e376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "marked-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5  6  8 12 22 23 24 25 26 27 28 29]\n",
      "[ 3  4  5  6  9 12 22 23 26 27 28]\n",
      "[22 23 29]\n",
      "[21 22 29]\n"
     ]
    }
   ],
   "source": [
    "new_data, _, rmv_ind = preprocess_train_data_split(tX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f0ceda3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  5  6 12 23 24 25 26 27 28] [ 4  5  6 12 22 23 24 25 26 27 28 29]\n",
      "[ 4  5  6 12 26 27 28] [ 4  5  6 12 22 26 27 28]\n",
      "[] 22\n",
      "[] 22\n"
     ]
    }
   ],
   "source": [
    "data_list, y_list, feat_ind = subdivide_data(tX, y)\n",
    "new_data_list = []\n",
    "for tx in data_list:\n",
    "    _, irr_ind = delete_irr_features(tx, 0.5)\n",
    "    _, norm_ind = normalize_data(tx)\n",
    "    print(irr_ind, norm_ind)\n",
    "    ind = norm_ind\n",
    "    ind = np.insert(ind, -1, irr_ind)\n",
    "    ind = np.unique(ind)\n",
    "    new_data = np.delete(tx, ind, axis=1)\n",
    "    new_data_list.append(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "comparable-compression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr_mat_0 = np.ma.corrcoef(new_data_list[0], rowvar=False)\n",
    "corr_mat_1 = np.ma.corrcoef(new_data_list[1], rowvar=False)\n",
    "corr_mat_2 = np.ma.corrcoef(new_data_list[2], rowvar=False)\n",
    "corr_mat_3 = np.ma.corrcoef(new_data_list[3], rowvar=False)\n",
    "\n",
    "corr_mat_list = [corr_mat_0, corr_mat_1, corr_mat_2, corr_mat_3]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for i in range(1, 5):\n",
    "    fig.add_subplot(4, 4, i)\n",
    "    plt.imshow(np.abs(corr_mat_list[i - 1]), cmap='Blues')\n",
    "    plt.xlabel('index of feature')\n",
    "    #plt.ylabel('index of feature')\n",
    "    #plt.savefig('../figs/corr_matrices.png', bbox_inches='tight')  \n",
    "    \n",
    "for i, corr in enumerate(corr_mat_list):\n",
    "    corr_mat_list[i][corr <= 0.9] = 0\n",
    "    corr_mat_list[i][corr > 0.9] = 1\n",
    "\n",
    "for i in range(5, 9):\n",
    "    fig.add_subplot(4, 4, i)\n",
    "    plt.imshow(np.abs(corr_mat_list[i - 5]), cmap='Blues')\n",
    "    plt.xlabel('index of feature')\n",
    "    #plt.ylabel('index of feature')\n",
    "    plt.savefig('../figs/corr_matrices.png', bbox_inches='tight')  \n",
    "plt.show() \n",
    "#plt.imshow(np.abs(corr_mat), cmap='Blues')\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "placed-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2]\n",
      " [ 3  9]\n",
      " [ 3 23]\n",
      " [ 3 29]\n",
      " [ 4  5]\n",
      " [ 9 21]\n",
      " [ 9 23]\n",
      " [ 9 29]\n",
      " [21 29]\n",
      " [22 29]\n",
      " [23 29]\n",
      " [26 29]]\n"
     ]
    }
   ],
   "source": [
    "corr_indices = np.argwhere(np.abs(np.triu(corr_mat - np.eye(30))) > 0.8)\n",
    "print(corr_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "simplified-decline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  3  4  9 21 22 23 26] [ 2  5  9 21 23 29]\n"
     ]
    }
   ],
   "source": [
    "unique_ind1 = np.unique(corr_indices[:, 0])\n",
    "unique_ind2 = np.unique(corr_indices[:, 1])\n",
    "print(unique_ind1, unique_ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "informative-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "len1 = len(unique_ind1)\n",
    "len2 = len(unique_ind2)\n",
    "corr_ind_reduce_short = (unique_ind1, unique_ind2)[len(unique_ind1) > len(unique_ind2)]\n",
    "corr_ind_reduce_big = (unique_ind1, unique_ind2)[len(unique_ind1) < len(unique_ind2)]\n",
    "corr_ind_to_keep = []\n",
    "for ind in corr_ind_reduce_short:\n",
    "    is_in = np.isin(ind, corr_ind_reduce_big)\n",
    "    if not is_in:\n",
    "        corr_ind_to_keep.append(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dried-clearance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11,)\n"
     ]
    }
   ],
   "source": [
    "all_ind = np.unique(corr_indices.flatten())\n",
    "print(all_ind.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "verbal-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_ind_to_throw = np.setdiff1d(all_ind, corr_ind_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "illegal-strip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  5, 29]), array([ 0,  3,  4,  9, 21, 22, 23, 26]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(corr_ind_to_keep), corr_ind_to_throw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-arrival",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-basic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-dubai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "connected-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep, throw = feature_selection(new_data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ordered-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  5, 29]), array([ 0,  3,  4,  9, 21, 22, 23, 26]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep, throw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-poker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d2f402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8864d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b5cc8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4,  5,  6,  8, 12, 22, 23, 24, 25, 26, 27, 28, 29])\n",
      " array([ 3,  4,  5,  6,  9, 12, 22, 23, 26, 27, 28])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AntoineDaeniker/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ind = np.array((rmv_ind[0], rmv_ind[1]))\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d1520b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Some errors were detected !\n    Line #3 (got 29 columns instead of 21)\n    Line #4 (got 28 columns instead of 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f3/3d8xjmhn3lb1y_bqwhqfy7t80000gn/T/ipykernel_21387/498828476.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../sgd_model_split.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/EPFL/Master 1/ML_course/ML_project/utils/io_utils.py\u001b[0m in \u001b[0;36mload_csv_data\u001b[0;34m(data_path, sub_sample)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_header\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0minput_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;31m# Raise an exception ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minvalid_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2080\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2081\u001b[0m             \u001b[0;31m# Issue a warning ?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Some errors were detected !\n    Line #3 (got 29 columns instead of 21)\n    Line #4 (got 28 columns instead of 21)"
     ]
    }
   ],
   "source": [
    "ws = load_csv_data('../sgd_model_split.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e1564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
